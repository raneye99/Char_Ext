{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing Features from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpusID</th>\n",
       "      <th>character</th>\n",
       "      <th>animacy</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "      <th>DP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ dragon ,  he ,  he ,  the dragon ,  He ,  hi...</td>\n",
       "      <td>dragon</td>\n",
       "      <td>dragon</td>\n",
       "      <td>43</td>\n",
       "      <td>2.499540</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess ,  the tsar 's daughter ,  her ,  h...</td>\n",
       "      <td>princess</td>\n",
       "      <td>princess</td>\n",
       "      <td>23</td>\n",
       "      <td>0.990763</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsar ,  tsar ,  father ,  tsar ,  her father...</td>\n",
       "      <td>tsar</td>\n",
       "      <td>tsar</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.065380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess' dog ,  a little dog that had follo...</td>\n",
       "      <td>princess' dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsarina ,  mother ,  tsarina ,  tsarina ]</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ who is stronger ,  who in this world was str...</td>\n",
       "      <td>who is stronger</td>\n",
       "      <td>stronger</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ dragon's statement ,  a tanner in the city o...</td>\n",
       "      <td>dragon's statement</td>\n",
       "      <td>statement</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Nikita ,  a tanner in the city of Kiev ,  Ni...</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>39</td>\n",
       "      <td>2.197784</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsar's coming ,  the tsar went in person to ...</td>\n",
       "      <td>tsar's coming</td>\n",
       "      <td>coming</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ his hands ,  his hands ,  his hands ]</td>\n",
       "      <td>his hands</td>\n",
       "      <td>hands</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ children ,  five thousand little children , ...</td>\n",
       "      <td>children</td>\n",
       "      <td>children</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.367136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ children's tears ,  their tears ,  tears ,  ...</td>\n",
       "      <td>children's tears</td>\n",
       "      <td>tears</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Nikita's tears ,  tears ]</td>\n",
       "      <td>Nikita's tears</td>\n",
       "      <td>tears</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ the other ,  the other ]</td>\n",
       "      <td>the other</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ those who do not know what it is ,  those wh...</td>\n",
       "      <td>those who do not know what it is</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corpusID character animacy  \\\n",
       "0    story1         1       1   \n",
       "1    story1         1       1   \n",
       "2    story1         1       1   \n",
       "3    story1         0       1   \n",
       "4    story1         1       1   \n",
       "5    story1         0       1   \n",
       "6    story1         0       1   \n",
       "7    story1         1       1   \n",
       "8    story1         0       1   \n",
       "9    story1         0       1   \n",
       "10   story1         0       1   \n",
       "11   story1         0       1   \n",
       "12   story1         0       1   \n",
       "13   story1         0       1   \n",
       "14   story1         0       1   \n",
       "\n",
       "                                          coref_chain  \\\n",
       "0   [ dragon ,  he ,  he ,  the dragon ,  He ,  hi...   \n",
       "1   [ princess ,  the tsar 's daughter ,  her ,  h...   \n",
       "2   [ tsar ,  tsar ,  father ,  tsar ,  her father...   \n",
       "3   [ princess' dog ,  a little dog that had follo...   \n",
       "4         [ tsarina ,  mother ,  tsarina ,  tsarina ]   \n",
       "5   [ who is stronger ,  who in this world was str...   \n",
       "6   [ dragon's statement ,  a tanner in the city o...   \n",
       "7   [ Nikita ,  a tanner in the city of Kiev ,  Ni...   \n",
       "8   [ tsar's coming ,  the tsar went in person to ...   \n",
       "9             [ his hands ,  his hands ,  his hands ]   \n",
       "10  [ children ,  five thousand little children , ...   \n",
       "11  [ children's tears ,  their tears ,  tears ,  ...   \n",
       "12                        [ Nikita's tears ,  tears ]   \n",
       "13                         [ the other ,  the other ]   \n",
       "14  [ those who do not know what it is ,  those wh...   \n",
       "\n",
       "                            chain_head head_of_head chain_len        CL   DP  \n",
       "0                              dragon        dragon        43  2.499540  1.0  \n",
       "1                            princess      princess        23  0.990763  1.0  \n",
       "2                                tsar          tsar         9 -0.065380  1.0  \n",
       "3                       princess' dog           dog         4 -0.442574  1.0  \n",
       "4                             tsarina       tsarina         4 -0.442574  1.0  \n",
       "5                     who is stronger      stronger         2 -0.593452  0.0  \n",
       "6                  dragon's statement     statement         3 -0.518013  0.0  \n",
       "7                              Nikita        Nikita        39  2.197784  1.0  \n",
       "8                       tsar's coming        coming         3 -0.518013  0.0  \n",
       "9                           his hands         hands         3 -0.518013  0.0  \n",
       "10                           children      children         5 -0.367136  1.0  \n",
       "11                   children's tears         tears         4 -0.442574  1.0  \n",
       "12                     Nikita's tears         tears         2 -0.593452  1.0  \n",
       "13                          the other         other         2 -0.593452  1.0  \n",
       "14   those who do not know what it is            is         2 -0.593452  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('popular')\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "PL_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "# for n in range(1,47):\n",
    "for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = PLcopath +'/story' + str(n) + '.txt'\n",
    "    storypath = PLpath + '/story' + str(n) + '.txt'\n",
    "    storyid = 'story'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    # # read in from intermediate files\n",
    "    # # list of features\n",
    "    # features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    # for f in features:\n",
    "    #     #empty list\n",
    "    #     feat = []\n",
    "    #     with open(PLInter + f + 'FeatureBoolean'+'/Story' + str(n) + '.txt', 'r') as doc:\n",
    "    #         for line in doc:\n",
    "    #             feat.append(eval(line.rstrip()))\n",
    "    \n",
    "    #     corpus[f] = feat\n",
    "\n",
    "    # #get ss feature\n",
    "    # sslist = preprocess.semantic_subj(storypath)\n",
    "    # #remove leading The/A's in the sematic list\n",
    "    # sslist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in sslist]\n",
    "    # pattern = '|'.join(sslist)\n",
    "    \n",
    "    # #create binary flag variable for ss feat\n",
    "    # corpus['SS'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    # corpus['SS'] = corpus['SS'].replace({True:1, False:0})\n",
    "\n",
    "    # #get ner feature\n",
    "    # nerlist = preprocess.ner_person(storypath)\n",
    "    # pattern = '|'.join(nerlist)\n",
    "\n",
    "    # #create binary flag variable for ss feat\n",
    "    # corpus['NER'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    # corpus['NER'] = corpus['NER'].replace({True:1, False:0})\n",
    "\n",
    "    # #create binary flag variable for wn feat\n",
    "    # #get wordnet synset of head of chain\n",
    "    # wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
    "   \n",
    "    # #fill blanks with unrelated word to person\n",
    "    # wn_input[0] = wn_input[0].fillna(wn.synset('strong.a.01'))\n",
    "   \n",
    "    # # get common synonym with person\n",
    "    # per = wn.synset('person.n.01')\n",
    "    # test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
    "   \n",
    "    # # test if head of chain related to person\n",
    "    # corpus['WN']= test[0]==per\n",
    "    # corpus['WN'] = corpus['WN'].replace({True:1, False:0})\n",
    "\n",
    "    # #get dp feat\n",
    "    # dplist = preprocess.dep_link(storypath)\n",
    "    # dplist = list(set(dplist))\n",
    "    # pattern='|'.join(dplist)\n",
    "\n",
    "    # #create binary flag variable for dp feat\n",
    "    # corpus['DP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    # corpus['DP'] = corpus['DP'].replace({True:1, False:0})\n",
    "\n",
    "    #get triple feat\n",
    "\n",
    "    #append to dataframe\n",
    "    PL_data = pd.concat([PL_data, corpus], ignore_index=True)\n",
    "\n",
    "PL_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tanner',\n",
       " 'Better',\n",
       " 'Let',\n",
       " 'He',\n",
       " 'the',\n",
       " 'Do',\n",
       " 'tears',\n",
       " 'dragon',\n",
       " 'One',\n",
       " 'dog',\n",
       " 'princess',\n",
       " 'but',\n",
       " 'those',\n",
       " 'we',\n",
       " 'father',\n",
       " 'they',\n",
       " '\"',\n",
       " 'whom',\n",
       " 'else',\n",
       " 'one',\n",
       " 'she',\n",
       " 'house',\n",
       " ',',\n",
       " 'furrow',\n",
       " 'us',\n",
       " 'At',\n",
       " 'what',\n",
       " 'he',\n",
       " 'you',\n",
       " 'it',\n",
       " 'children',\n",
       " 'tsar',\n",
       " 'that',\n",
       " 'Nikita',\n",
       " 'Upon',\n",
       " 'Very']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arc_loss': 0.39981868863105774,\n",
       " 'tag_loss': 0.5472878217697144,\n",
       " 'loss': 0.9471064805984497,\n",
       " 'words': ['James',\n",
       "  'Lee',\n",
       "  'ate',\n",
       "  'some',\n",
       "  'cheese',\n",
       "  'while',\n",
       "  'thinking',\n",
       "  'about',\n",
       "  'the',\n",
       "  'play',\n",
       "  ',',\n",
       "  'but',\n",
       "  'I',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  'I',\n",
       "  'like',\n",
       "  'him',\n",
       "  'very',\n",
       "  'much'],\n",
       " 'pos': ['PROPN',\n",
       "  'PROPN',\n",
       "  'VERB',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'SCONJ',\n",
       "  'VERB',\n",
       "  'ADP',\n",
       "  'DET',\n",
       "  'NOUN',\n",
       "  'PUNCT',\n",
       "  'CCONJ',\n",
       "  'PRON',\n",
       "  'AUX',\n",
       "  'PART',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  'VERB',\n",
       "  'PRON',\n",
       "  'ADV',\n",
       "  'ADV'],\n",
       " 'predicted_dependencies': ['nsubj',\n",
       "  'nsubj',\n",
       "  'root',\n",
       "  'dep',\n",
       "  'dep',\n",
       "  'prep',\n",
       "  'dep',\n",
       "  'prep',\n",
       "  'det',\n",
       "  'pobj',\n",
       "  'punct',\n",
       "  'advmod',\n",
       "  'nsubj',\n",
       "  'aux',\n",
       "  'neg',\n",
       "  'dep',\n",
       "  'dep',\n",
       "  'advmod',\n",
       "  'dep',\n",
       "  'advmod',\n",
       "  'dobj'],\n",
       " 'predicted_heads': [3,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  7,\n",
       "  10,\n",
       "  8,\n",
       "  3,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  3,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  21,\n",
       "  19],\n",
       " 'hierplane_tree': {'text': \"James Lee ate some cheese while thinking about the play , but I do n't think I like him very much\",\n",
       "  'root': {'word': 'ate',\n",
       "   'nodeType': 'root',\n",
       "   'attributes': ['VERB'],\n",
       "   'link': 'root',\n",
       "   'spans': [{'start': 10, 'end': 14}],\n",
       "   'children': [{'word': 'James',\n",
       "     'nodeType': 'nsubj',\n",
       "     'attributes': ['PROPN'],\n",
       "     'link': 'nsubj',\n",
       "     'spans': [{'start': 0, 'end': 6}]},\n",
       "    {'word': 'Lee',\n",
       "     'nodeType': 'nsubj',\n",
       "     'attributes': ['PROPN'],\n",
       "     'link': 'nsubj',\n",
       "     'spans': [{'start': 6, 'end': 10}]},\n",
       "    {'word': 'cheese',\n",
       "     'nodeType': 'dep',\n",
       "     'attributes': ['NOUN'],\n",
       "     'link': 'dep',\n",
       "     'spans': [{'start': 19, 'end': 26}],\n",
       "     'children': [{'word': 'some',\n",
       "       'nodeType': 'dep',\n",
       "       'attributes': ['DET'],\n",
       "       'link': 'dep',\n",
       "       'spans': [{'start': 14, 'end': 19}]}]},\n",
       "    {'word': 'while',\n",
       "     'nodeType': 'prep',\n",
       "     'attributes': ['SCONJ'],\n",
       "     'link': 'prep',\n",
       "     'spans': [{'start': 26, 'end': 32}]},\n",
       "    {'word': 'thinking',\n",
       "     'nodeType': 'dep',\n",
       "     'attributes': ['VERB'],\n",
       "     'link': 'dep',\n",
       "     'spans': [{'start': 32, 'end': 41}],\n",
       "     'children': [{'word': 'about',\n",
       "       'nodeType': 'prep',\n",
       "       'attributes': ['ADP'],\n",
       "       'link': 'prep',\n",
       "       'spans': [{'start': 41, 'end': 47}],\n",
       "       'children': [{'word': 'play',\n",
       "         'nodeType': 'pobj',\n",
       "         'attributes': ['NOUN'],\n",
       "         'link': 'pobj',\n",
       "         'spans': [{'start': 51, 'end': 56}],\n",
       "         'children': [{'word': 'the',\n",
       "           'nodeType': 'det',\n",
       "           'attributes': ['DET'],\n",
       "           'link': 'det',\n",
       "           'spans': [{'start': 47, 'end': 51}]}]}]}]},\n",
       "    {'word': ',',\n",
       "     'nodeType': 'punct',\n",
       "     'attributes': ['PUNCT'],\n",
       "     'link': 'punct',\n",
       "     'spans': [{'start': 56, 'end': 58}]},\n",
       "    {'word': 'think',\n",
       "     'nodeType': 'dep',\n",
       "     'attributes': ['VERB'],\n",
       "     'link': 'dep',\n",
       "     'spans': [{'start': 71, 'end': 77}],\n",
       "     'children': [{'word': 'but',\n",
       "       'nodeType': 'advmod',\n",
       "       'attributes': ['CCONJ'],\n",
       "       'link': 'advmod',\n",
       "       'spans': [{'start': 58, 'end': 62}]},\n",
       "      {'word': 'I',\n",
       "       'nodeType': 'nsubj',\n",
       "       'attributes': ['PRON'],\n",
       "       'link': 'nsubj',\n",
       "       'spans': [{'start': 62, 'end': 64}]},\n",
       "      {'word': 'do',\n",
       "       'nodeType': 'aux',\n",
       "       'attributes': ['AUX'],\n",
       "       'link': 'aux',\n",
       "       'spans': [{'start': 64, 'end': 67}]},\n",
       "      {'word': \"n't\",\n",
       "       'nodeType': 'neg',\n",
       "       'attributes': ['PART'],\n",
       "       'link': 'neg',\n",
       "       'spans': [{'start': 67, 'end': 71}]},\n",
       "      {'word': 'I',\n",
       "       'nodeType': 'dep',\n",
       "       'attributes': ['PRON'],\n",
       "       'link': 'dep',\n",
       "       'spans': [{'start': 77, 'end': 79}],\n",
       "       'children': [{'word': 'like',\n",
       "         'nodeType': 'advmod',\n",
       "         'attributes': ['VERB'],\n",
       "         'link': 'advmod',\n",
       "         'spans': [{'start': 79, 'end': 84}],\n",
       "         'children': [{'word': 'him',\n",
       "           'nodeType': 'dep',\n",
       "           'attributes': ['PRON'],\n",
       "           'link': 'dep',\n",
       "           'spans': [{'start': 84, 'end': 88}],\n",
       "           'children': [{'word': 'much',\n",
       "             'nodeType': 'dobj',\n",
       "             'attributes': ['ADV'],\n",
       "             'link': 'dobj',\n",
       "             'spans': [{'start': 93, 'end': 98}],\n",
       "             'children': [{'word': 'very',\n",
       "               'nodeType': 'advmod',\n",
       "               'attributes': ['ADV'],\n",
       "               'link': 'advmod',\n",
       "               'spans': [{'start': 88, 'end': 93}]}]}]}]}]}]}]},\n",
       "  'nodeTypeToStyle': {'root': ['color5', 'strong'],\n",
       "   'dep': ['color5', 'strong'],\n",
       "   'nsubj': ['color1'],\n",
       "   'nsubjpass': ['color1'],\n",
       "   'csubj': ['color1'],\n",
       "   'csubjpass': ['color1'],\n",
       "   'pobj': ['color2'],\n",
       "   'dobj': ['color2'],\n",
       "   'iobj': ['color2'],\n",
       "   'mark': ['color2'],\n",
       "   'pcomp': ['color2'],\n",
       "   'xcomp': ['color2'],\n",
       "   'ccomp': ['color2'],\n",
       "   'acomp': ['color2'],\n",
       "   'aux': ['color3'],\n",
       "   'cop': ['color3'],\n",
       "   'det': ['color3'],\n",
       "   'conj': ['color3'],\n",
       "   'cc': ['color3'],\n",
       "   'prep': ['color3'],\n",
       "   'number': ['color3'],\n",
       "   'possesive': ['color3'],\n",
       "   'poss': ['color3'],\n",
       "   'discourse': ['color3'],\n",
       "   'expletive': ['color3'],\n",
       "   'prt': ['color3'],\n",
       "   'advcl': ['color3'],\n",
       "   'mod': ['color4'],\n",
       "   'amod': ['color4'],\n",
       "   'tmod': ['color4'],\n",
       "   'quantmod': ['color4'],\n",
       "   'npadvmod': ['color4'],\n",
       "   'infmod': ['color4'],\n",
       "   'advmod': ['color4'],\n",
       "   'appos': ['color4'],\n",
       "   'nn': ['color4'],\n",
       "   'neg': ['color0'],\n",
       "   'punct': ['color0']},\n",
       "  'linkToPosition': {'nsubj': 'left',\n",
       "   'nsubjpass': 'left',\n",
       "   'csubj': 'left',\n",
       "   'csubjpass': 'left',\n",
       "   'pobj': 'right',\n",
       "   'dobj': 'right',\n",
       "   'iobj': 'right',\n",
       "   'pcomp': 'right',\n",
       "   'xcomp': 'right',\n",
       "   'ccomp': 'right',\n",
       "   'acomp': 'right'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demo use for allenlp\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "ex_sent = \"James Lee ate some cheese while thinking about the play, but I don't think I like him very much\"\n",
    "\n",
    "#load dp predictor\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/biaffine-dependency-parser-ptb-2020.04.06.tar.gz\")\n",
    "labels = predictor.predict(\n",
    "    sentence = ex_sent\n",
    "    )\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Features from Intermediate File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpusID</th>\n",
       "      <th>character</th>\n",
       "      <th>animacy</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "      <th>CN</th>\n",
       "      <th>Dep</th>\n",
       "      <th>NER</th>\n",
       "      <th>SS</th>\n",
       "      <th>Triple</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ dragon ,  he ,  he ,  the dragon ,  He ,  hi...</td>\n",
       "      <td>dragon</td>\n",
       "      <td>dragon</td>\n",
       "      <td>43</td>\n",
       "      <td>2.499540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess ,  the tsar 's daughter ,  her ,  h...</td>\n",
       "      <td>princess</td>\n",
       "      <td>princess</td>\n",
       "      <td>23</td>\n",
       "      <td>0.990763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsar ,  tsar ,  father ,  tsar ,  her father...</td>\n",
       "      <td>tsar</td>\n",
       "      <td>tsar</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.065380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess' dog ,  a little dog that had follo...</td>\n",
       "      <td>princess' dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsarina ,  mother ,  tsarina ,  tsarina ]</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ who is stronger ,  who in this world was str...</td>\n",
       "      <td>who is stronger</td>\n",
       "      <td>stronger</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ dragon's statement ,  a tanner in the city o...</td>\n",
       "      <td>dragon's statement</td>\n",
       "      <td>statement</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Nikita ,  a tanner in the city of Kiev ,  Ni...</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>39</td>\n",
       "      <td>2.197784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsar's coming ,  the tsar went in person to ...</td>\n",
       "      <td>tsar's coming</td>\n",
       "      <td>coming</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ his hands ,  his hands ,  his hands ]</td>\n",
       "      <td>his hands</td>\n",
       "      <td>hands</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ children ,  five thousand little children , ...</td>\n",
       "      <td>children</td>\n",
       "      <td>children</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.367136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ children's tears ,  their tears ,  tears ,  ...</td>\n",
       "      <td>children's tears</td>\n",
       "      <td>tears</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Nikita's tears ,  tears ]</td>\n",
       "      <td>Nikita's tears</td>\n",
       "      <td>tears</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ the other ,  the other ]</td>\n",
       "      <td>the other</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ those who do not know what it is ,  those wh...</td>\n",
       "      <td>those who do not know what it is</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corpusID character animacy  \\\n",
       "0    story1         1       1   \n",
       "1    story1         1       1   \n",
       "2    story1         1       1   \n",
       "3    story1         0       1   \n",
       "4    story1         1       1   \n",
       "5    story1         0       1   \n",
       "6    story1         0       1   \n",
       "7    story1         1       1   \n",
       "8    story1         0       1   \n",
       "9    story1         0       1   \n",
       "10   story1         0       1   \n",
       "11   story1         0       1   \n",
       "12   story1         0       1   \n",
       "13   story1         0       1   \n",
       "14   story1         0       1   \n",
       "\n",
       "                                          coref_chain  \\\n",
       "0   [ dragon ,  he ,  he ,  the dragon ,  He ,  hi...   \n",
       "1   [ princess ,  the tsar 's daughter ,  her ,  h...   \n",
       "2   [ tsar ,  tsar ,  father ,  tsar ,  her father...   \n",
       "3   [ princess' dog ,  a little dog that had follo...   \n",
       "4         [ tsarina ,  mother ,  tsarina ,  tsarina ]   \n",
       "5   [ who is stronger ,  who in this world was str...   \n",
       "6   [ dragon's statement ,  a tanner in the city o...   \n",
       "7   [ Nikita ,  a tanner in the city of Kiev ,  Ni...   \n",
       "8   [ tsar's coming ,  the tsar went in person to ...   \n",
       "9             [ his hands ,  his hands ,  his hands ]   \n",
       "10  [ children ,  five thousand little children , ...   \n",
       "11  [ children's tears ,  their tears ,  tears ,  ...   \n",
       "12                        [ Nikita's tears ,  tears ]   \n",
       "13                         [ the other ,  the other ]   \n",
       "14  [ those who do not know what it is ,  those wh...   \n",
       "\n",
       "                            chain_head head_of_head chain_len        CL   CN  \\\n",
       "0                              dragon        dragon        43  2.499540  1.0   \n",
       "1                            princess      princess        23  0.990763  1.0   \n",
       "2                                tsar          tsar         9 -0.065380  1.0   \n",
       "3                       princess' dog           dog         4 -0.442574  1.0   \n",
       "4                             tsarina       tsarina         4 -0.442574  1.0   \n",
       "5                     who is stronger      stronger         2 -0.593452  0.0   \n",
       "6                  dragon's statement     statement         3 -0.518013  0.0   \n",
       "7                              Nikita        Nikita        39  2.197784  0.0   \n",
       "8                       tsar's coming        coming         3 -0.518013  0.0   \n",
       "9                           his hands         hands         3 -0.518013  0.0   \n",
       "10                           children      children         5 -0.367136  0.0   \n",
       "11                   children's tears         tears         4 -0.442574  0.0   \n",
       "12                     Nikita's tears         tears         2 -0.593452  0.0   \n",
       "13                          the other         other         2 -0.593452  0.0   \n",
       "14   those who do not know what it is            is         2 -0.593452  0.0   \n",
       "\n",
       "    Dep  NER   SS  Triple   WN  \n",
       "0   1.0  0.0  1.0     1.0  0.0  \n",
       "1   1.0  0.0  1.0     0.0  1.0  \n",
       "2   1.0  0.0  1.0     1.0  1.0  \n",
       "3   1.0  0.0  1.0     1.0  0.0  \n",
       "4   1.0  0.0  1.0     0.0  1.0  \n",
       "5   0.0  0.0  0.0     0.0  0.0  \n",
       "6   0.0  0.0  0.0     0.0  0.0  \n",
       "7   1.0  1.0  1.0     0.0  0.0  \n",
       "8   0.0  0.0  0.0     0.0  0.0  \n",
       "9   1.0  0.0  1.0     0.0  0.0  \n",
       "10  1.0  0.0  1.0     0.0  0.0  \n",
       "11  1.0  0.0  1.0     0.0  0.0  \n",
       "12  1.0  1.0  1.0     0.0  0.0  \n",
       "13  0.0  0.0  0.0     0.0  0.0  \n",
       "14  0.0  0.0  1.0     0.0  0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "PL_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "# for n in range(1,47):\n",
    "for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = PLcopath +'/story' + str(n) + '.txt'\n",
    "    storypath = PLpath + '/story' + str(n) + '.txt'\n",
    "    storyid = 'story'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    #read in from intermediate files\n",
    "    #list of features\n",
    "    features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    for f in features:\n",
    "        #empty list\n",
    "        feat = []\n",
    "        with open(PLInter + f + 'FeatureBoolean'+'/Story' + str(n) + '.txt', 'r') as doc:\n",
    "            for line in doc:\n",
    "                feat.append(eval(line.rstrip()))\n",
    "    \n",
    "        corpus[f] = feat\n",
    "    \n",
    "    #append to dataframe\n",
    "    PL_data = pd.concat([PL_data, corpus], ignore_index=True)\n",
    "PL_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90775194 0.9124031  0.91007752 0.91007752 0.90859799 0.91402014\n",
      " 0.9070488  0.91092177 0.91324555 0.91247095]\n",
      "[0.92361111 0.875      0.90972222 0.90277778 0.90909091 0.8951049\n",
      " 0.92307692 0.91608392 0.86713287 0.88811189]\n",
      "[0.82212257 0.8320951  0.82789318 0.82738095 0.82440476 0.83308271\n",
      " 0.82035928 0.82962963 0.83577713 0.83109118]\n",
      "[0.86419753 0.75675676 0.82191781 0.82051282 0.82191781 0.81012658\n",
      " 0.85333333 0.83783784 0.71641791 0.78947368]\n"
     ]
    }
   ],
   "source": [
    "# simple model \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_y = PL_data[\"character\"].astype('int')\n",
    "data_x = PL_data[[\"CL\", \"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=0)\n",
    "\n",
    "rbf_svc = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "cv_results = cross_validate(rbf_svc, X_train, y_train, cv = 10, scoring=('f1', 'accuracy'), return_train_score=True)\n",
    "\n",
    "print(cv_results['train_accuracy'])\n",
    "print(cv_results['test_accuracy'])\n",
    "print(cv_results['train_f1'])\n",
    "print(cv_results['test_f1'])\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=10, test_size=.2, random_state=42)\n",
    "\n",
    "# C_range = np.logspace(-2,10,13)\n",
    "# gamma_range = np.logspace(-9,3,13)\n",
    "\n",
    "# grid = GridSearchCV(svm.SVC(kernel='rbf'), param_grid=dict(gamma = gamma_range, C= C_range), cv=cv)\n",
    "\n",
    "# grid.fit(X_train,y_train)\n",
    "\n",
    "# print(grid.best_params_, grid.best_score_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('char_ext_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ab110a997218d36eb782d7088a10d031e5f038772d20aa5829c90f0ae252251"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
