{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing Features from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:66: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  corpus['SS'] = corpus['head_of_head'].str.contains(pattern)\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpusID</th>\n",
       "      <th>character</th>\n",
       "      <th>animacy</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "      <th>SS</th>\n",
       "      <th>NER</th>\n",
       "      <th>WN</th>\n",
       "      <th>DP</th>\n",
       "      <th>TP</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ dragon ,  he ,  he ,  the dragon ,  He ,  hi...</td>\n",
       "      <td>dragon</td>\n",
       "      <td>dragon</td>\n",
       "      <td>43</td>\n",
       "      <td>2.499540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess ,  the tsar 's daughter ,  her ,  h...</td>\n",
       "      <td>princess</td>\n",
       "      <td>princess</td>\n",
       "      <td>23</td>\n",
       "      <td>0.990763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsar ,  tsar ,  father ,  tsar ,  her father...</td>\n",
       "      <td>tsar</td>\n",
       "      <td>tsar</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.065380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess' dog ,  a little dog that had follo...</td>\n",
       "      <td>princess' dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsarina ,  mother ,  tsarina ,  tsarina ]</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ the entire enemy army ,  the enemy army ,  h...</td>\n",
       "      <td>the entire enemy army</td>\n",
       "      <td>army</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.308434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ this ,  the best solution ]</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.604613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ a horse ,  a horse ]</td>\n",
       "      <td>a horse</td>\n",
       "      <td>horse</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.604613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ an even better horse ,  his horse ,  his hor...</td>\n",
       "      <td>an even better horse</td>\n",
       "      <td>horse</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.486142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ the hand ,  the hand ]</td>\n",
       "      <td>the hand</td>\n",
       "      <td>hand</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.604613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1912 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpusID character animacy  \\\n",
       "0      story1         1       1   \n",
       "1      story1         1       1   \n",
       "2      story1         1       1   \n",
       "3      story1         0       1   \n",
       "4      story1         1       1   \n",
       "...       ...       ...     ...   \n",
       "1907  story46         0       1   \n",
       "1908  story46         0       1   \n",
       "1909  story46         0       1   \n",
       "1910  story46         0       1   \n",
       "1911  story46         0       1   \n",
       "\n",
       "                                            coref_chain  \\\n",
       "0     [ dragon ,  he ,  he ,  the dragon ,  He ,  hi...   \n",
       "1     [ princess ,  the tsar 's daughter ,  her ,  h...   \n",
       "2     [ tsar ,  tsar ,  father ,  tsar ,  her father...   \n",
       "3     [ princess' dog ,  a little dog that had follo...   \n",
       "4           [ tsarina ,  mother ,  tsarina ,  tsarina ]   \n",
       "...                                                 ...   \n",
       "1907  [ the entire enemy army ,  the enemy army ,  h...   \n",
       "1908                      [ this ,  the best solution ]   \n",
       "1909                             [ a horse ,  a horse ]   \n",
       "1910  [ an even better horse ,  his horse ,  his hor...   \n",
       "1911                           [ the hand ,  the hand ]   \n",
       "\n",
       "                   chain_head head_of_head chain_len        CL   SS  NER   WN  \\\n",
       "0                     dragon        dragon        43  2.499540  1.0  0.0  0.0   \n",
       "1                   princess      princess        23  0.990763  1.0  0.0  1.0   \n",
       "2                       tsar          tsar         9 -0.065380  1.0  0.0  1.0   \n",
       "3              princess' dog           dog         4 -0.442574  1.0  0.0  0.0   \n",
       "4                    tsarina       tsarina         4 -0.442574  1.0  0.0  1.0   \n",
       "...                       ...          ...       ...       ...  ...  ...  ...   \n",
       "1907   the entire enemy army          army         7 -0.308434  0.0  0.0  0.0   \n",
       "1908                    this          this         2 -0.604613  1.0  0.0  0.0   \n",
       "1909                 a horse         horse         2 -0.604613  0.0  0.0  0.0   \n",
       "1910    an even better horse         horse         4 -0.486142  0.0  0.0  0.0   \n",
       "1911                the hand          hand         2 -0.604613  0.0  0.0  0.0   \n",
       "\n",
       "       DP   TP   CN  \n",
       "0     1.0  1.0  1.0  \n",
       "1     1.0  1.0  1.0  \n",
       "2     1.0  1.0  1.0  \n",
       "3     1.0  1.0  1.0  \n",
       "4     1.0  1.0  1.0  \n",
       "...   ...  ...  ...  \n",
       "1907  0.0  0.0  0.0  \n",
       "1908  1.0  0.0  0.0  \n",
       "1909  0.0  0.0  0.0  \n",
       "1910  0.0  0.0  0.0  \n",
       "1911  1.0  0.0  0.0  \n",
       "\n",
       "[1912 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "import yake\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('popular')\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENcopath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENTexts'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "CENInter = src_path + '/output/IntermediateFilesCEN/'\n",
    "ONInter = src_path + '/output/IntermediateFilesON/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "PL_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "for n in range(1,47):\n",
    "# for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = PLcopath +'/story' + str(n) + '.txt'\n",
    "    storypath = PLpath + '/story' + str(n) + '.txt'\n",
    "    storyid = 'story'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    # read in from intermediate files\n",
    "    # list of features\n",
    "    # features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    # for f in features:\n",
    "    #     #empty list\n",
    "    #     feat = []\n",
    "    #     with open(PLInter + f + 'FeatureBoolean'+'/Story' + str(n) + '.txt', 'r') as doc:\n",
    "    #         for line in doc:\n",
    "    #             feat.append(eval(line.rstrip()))\n",
    "    \n",
    "    #     corpus[f] = feat\n",
    "\n",
    "    #get ss feature\n",
    "    sslist = preprocess.semantic_subj(storypath)\n",
    "    #remove leading The/A's in the sematic list\n",
    "    sslist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in sslist]\n",
    "    pattern = '|'.join(sslist)\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "    \n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['SS'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['SS'] = corpus['SS'].replace({True:1, False:0})\n",
    "\n",
    "    #get ner feature\n",
    "    nerlist = preprocess.ner_person(storypath)\n",
    "    pattern = '|'.join(nerlist)\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "    pattern = pattern.replace('[','')\n",
    "    pattern = pattern.replace(']','')\n",
    "\n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['NER'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['NER'] = corpus['NER'].replace({True:1, False:0})\n",
    "\n",
    "\n",
    "    #create binary flag variable for wn feat\n",
    "    #get wordnet synset of head of chain\n",
    "    wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
    "   \n",
    "    #fill blanks with unrelated word to person\n",
    "    wn_input[0] = wn_input[0].fillna(wn.synset('strong.a.01'))\n",
    "   \n",
    "    # get common synonym with person\n",
    "    per = wn.synset('person.n.01')\n",
    "    test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
    "   \n",
    "    # test if head of chain related to person\n",
    "    corpus['WN']= test[0]==per\n",
    "    corpus['WN'] = corpus['WN'].replace({True:1, False:0})\n",
    "\n",
    "    #get dp feat\n",
    "    dplist = preprocess.dep_link(storypath)\n",
    "    dplist = list(set(dplist))\n",
    "    pattern='|'.join(dplist)\n",
    "    #remove punct\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace(')|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "\n",
    "    #create binary flag variable for dp feat\n",
    "    corpus['DP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['DP'] = corpus['DP'].replace({True:1, False:0})\n",
    "\n",
    "    #get triple feat\n",
    "    tplist = preprocess.triple(storypath)\n",
    "    tplist = list(set(tplist))\n",
    "    #remove leading The/A's in the sematic list\n",
    "    tplist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in tplist]\n",
    "    pattern='|'.join(tplist)\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace(')|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "\n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['TP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['TP'] = corpus['TP'].replace({True:1, False:0})\n",
    "\n",
    "    # get conceptnet feat\n",
    "    urlreq = 'https://api.conceptnet.io/c/en/'+corpus['head_of_head']\n",
    "\n",
    "    #default no presence of person mentioned\n",
    "    corpus['CN'] = 0\n",
    "\n",
    "    for i in range(len(urlreq)):\n",
    "\n",
    "        #make request to concept net api\n",
    "        response = requests.get(urlreq[i])\n",
    "        obj = response.json()\n",
    "        #get list of edges\n",
    "        cnlist = [edge['@id'] for edge in obj['edges']]\n",
    "\n",
    "        #if person is in list then flag\n",
    "        if any('person' in s for s in cnlist):\n",
    "            val = 1\n",
    "            corpus['CN'][i]=val\n",
    "    \n",
    "    #create feature for freq of head of chain term in text\n",
    "    tf_dict = preprocess.term_freq(storypath)\n",
    "    corpus['TF'] = corpus['head_of_head'].map(tf_dict)\n",
    "\n",
    "    #create feature that contains keyword extraction score from yake\n",
    "    f = open(storypath, 'r', encoding='ISO-8859-1')\n",
    "    text = f.read()\n",
    "    f.close()  \n",
    "\n",
    "    kw_extractor = yake.KeywordExtractor(top = 100)\n",
    "    keywords = dict(kw_extractor.extract_keywords(text))\n",
    "    corpus['YK_SC'] = corpus['head_of_head'].map(keywords)\n",
    "    corpus['YK_SC'] = corpus['YK_SC'].fillna(100)\n",
    "\n",
    "    #append to dataframe\n",
    "    PL_data = pd.concat([PL_data, corpus], ignore_index=True)\n",
    "\n",
    "PL_data.to_csv(\"Data/PL.csv\")\n",
    "PL_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CEN Datasest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/spacy/util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eileen/miniconda3/envs/char_ext_2/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "/tmp/ipykernel_461268/2464705671.py:94: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_461268/2464705671.py:101: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_461268/2464705671.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpusID</th>\n",
       "      <th>character</th>\n",
       "      <th>animacy</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "      <th>SS</th>\n",
       "      <th>NER</th>\n",
       "      <th>WN</th>\n",
       "      <th>DP</th>\n",
       "      <th>TP</th>\n",
       "      <th>CN</th>\n",
       "      <th>TF</th>\n",
       "      <th>YK_SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Barold ,  He ,  him ,  Barold 's ,  Barold ,...</td>\n",
       "      <td>Barold</td>\n",
       "      <td>Barold</td>\n",
       "      <td>28</td>\n",
       "      <td>2.837451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.035029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Lucia ,  Lucia ,  Lucia ,  Lucia , who had b...</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>17</td>\n",
       "      <td>1.487132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.034517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Octavia ,  Octavia ,  I ,  Octavia ,  I ,  M...</td>\n",
       "      <td>Octavia</td>\n",
       "      <td>Octavia</td>\n",
       "      <td>24</td>\n",
       "      <td>2.346426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.015361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Lady Theobald 's ,  furious Lady Theobald , ...</td>\n",
       "      <td>Lady Theobald 's</td>\n",
       "      <td>'s</td>\n",
       "      <td>12</td>\n",
       "      <td>0.873350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Octavia and Lord Lansdowne ,  Lord Lansdowne...</td>\n",
       "      <td>Octavia and Lord Lansdowne</td>\n",
       "      <td>Lansdowne</td>\n",
       "      <td>16</td>\n",
       "      <td>1.364375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.039249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ them ]</td>\n",
       "      <td>them</td>\n",
       "      <td>them</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ Giovanni 's shoulders ]</td>\n",
       "      <td>Giovanni 's shoulders</td>\n",
       "      <td>shoulders</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ his angry eyes ]</td>\n",
       "      <td>his angry eyes</td>\n",
       "      <td>eyes</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.082623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ My beloved ,  I ,  I ,  I ,  Especially I , ...</td>\n",
       "      <td>My beloved</td>\n",
       "      <td>beloved</td>\n",
       "      <td>10</td>\n",
       "      <td>0.812119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ you ]</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5808 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpusID character animacy  \\\n",
       "0      Novel1         1       1   \n",
       "1      Novel1         1       1   \n",
       "2      Novel1         1       1   \n",
       "3      Novel1         1       1   \n",
       "4      Novel1         1       1   \n",
       "...       ...       ...     ...   \n",
       "5803  Novel30         0       0   \n",
       "5804  Novel30         0       0   \n",
       "5805  Novel30         0       0   \n",
       "5806  Novel30         0       1   \n",
       "5807  Novel30         0       1   \n",
       "\n",
       "                                            coref_chain  \\\n",
       "0     [ Barold ,  He ,  him ,  Barold 's ,  Barold ,...   \n",
       "1     [ Lucia ,  Lucia ,  Lucia ,  Lucia , who had b...   \n",
       "2     [ Octavia ,  Octavia ,  I ,  Octavia ,  I ,  M...   \n",
       "3     [ Lady Theobald 's ,  furious Lady Theobald , ...   \n",
       "4     [ Octavia and Lord Lansdowne ,  Lord Lansdowne...   \n",
       "...                                                 ...   \n",
       "5803                                           [ them ]   \n",
       "5804                          [ Giovanni 's shoulders ]   \n",
       "5805                                 [ his angry eyes ]   \n",
       "5806  [ My beloved ,  I ,  I ,  I ,  Especially I , ...   \n",
       "5807                                            [ you ]   \n",
       "\n",
       "                        chain_head head_of_head chain_len        CL   SS  NER  \\\n",
       "0                          Barold        Barold        28  2.837451  0.0  1.0   \n",
       "1                           Lucia         Lucia        17  1.487132  1.0  1.0   \n",
       "2                         Octavia       Octavia        24  2.346426  1.0  1.0   \n",
       "3                Lady Theobald 's            's        12  0.873350  0.0  0.0   \n",
       "4      Octavia and Lord Lansdowne     Lansdowne        16  1.364375  0.0  1.0   \n",
       "...                            ...          ...       ...       ...  ...  ...   \n",
       "5803                         them          them         1 -0.218213  1.0  0.0   \n",
       "5804        Giovanni 's shoulders     shoulders         1 -0.218213  0.0  0.0   \n",
       "5805               his angry eyes          eyes         1 -0.218213  1.0  0.0   \n",
       "5806                   My beloved       beloved        10  0.812119  0.0  0.0   \n",
       "5807                          you           you         1 -0.218213  1.0  0.0   \n",
       "\n",
       "       WN   DP   TP   CN        TF       YK_SC  \n",
       "0     0.0  1.0  1.0  0.0  0.003622    0.035029  \n",
       "1     0.0  1.0  1.0  0.0  0.004074    0.034517  \n",
       "2     0.0  1.0  1.0  0.0  0.006338    0.015361  \n",
       "3     0.0  0.0  0.0  0.0  0.008601  100.000000  \n",
       "4     0.0  1.0  0.0  0.0  0.002716    0.039249  \n",
       "...   ...  ...  ...  ...       ...         ...  \n",
       "5803  0.0  1.0  1.0  0.0  0.000000  100.000000  \n",
       "5804  0.0  0.0  0.0  0.0  0.000409  100.000000  \n",
       "5805  0.0  1.0  0.0  0.0  0.002456    0.082623  \n",
       "5806  1.0  0.0  0.0  1.0  0.000409  100.000000  \n",
       "5807  0.0  1.0  1.0  0.0  0.000000  100.000000  \n",
       "\n",
       "[5808 rows x 16 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "import yake\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('popular')\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENcopath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENTexts'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "CENInter = src_path + '/output/IntermediateFilesCEN/'\n",
    "ONInter = src_path + '/output/IntermediateFilesON/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "CEN_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "for n in range(1,31):\n",
    "# for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = CENcopath +'/Novel' + str(n) + '.txt'\n",
    "    storypath = CENpath + '/Novel' + str(n) + '.txt'\n",
    "    storyid = 'Novel'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    # read in from intermediate files\n",
    "    # list of features\n",
    "    # features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    # for f in features:\n",
    "    #     #empty list\n",
    "    #     feat = []\n",
    "    #     with open(PLInter + f + 'FeatureBoolean'+'/Story' + str(n) + '.txt', 'r') as doc:\n",
    "    #         for line in doc:\n",
    "    #             feat.append(eval(line.rstrip()))\n",
    "    \n",
    "    #     corpus[f] = feat\n",
    "\n",
    "    #get ss feature\n",
    "    sslist = preprocess.semantic_subj(storypath)\n",
    "    #remove leading The/A's in the sematic list\n",
    "    sslist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in sslist]\n",
    "    pattern = '|'.join(sslist)\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "    \n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['SS'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['SS'] = corpus['SS'].replace({True:1, False:0})\n",
    "\n",
    "    #get ner feature\n",
    "    nerlist = preprocess.ner_person(storypath)\n",
    "    pattern = '|'.join(nerlist)\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "    pattern = pattern.replace('[','')\n",
    "    pattern = pattern.replace(']','')\n",
    "\n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['NER'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['NER'] = corpus['NER'].replace({True:1, False:0})\n",
    "\n",
    "\n",
    "    #create binary flag variable for wn feat\n",
    "    #get wordnet synset of head of chain\n",
    "    wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
    "   \n",
    "    #fill blanks with unrelated word to person\n",
    "    wn_input[0] = wn_input[0].fillna(wn.synset('strong.a.01'))\n",
    "   \n",
    "    # get common synonym with person\n",
    "    per = wn.synset('person.n.01')\n",
    "    test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
    "   \n",
    "    # test if head of chain related to person\n",
    "    corpus['WN']= test[0]==per\n",
    "    corpus['WN'] = corpus['WN'].replace({True:1, False:0})\n",
    "\n",
    "    #get dp feat\n",
    "    dplist = preprocess.dep_link(storypath)\n",
    "    dplist = list(set(dplist))\n",
    "    pattern='|'.join(dplist)\n",
    "    #remove punct\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace(')|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "\n",
    "    #create binary flag variable for dp feat\n",
    "    corpus['DP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['DP'] = corpus['DP'].replace({True:1, False:0})\n",
    "\n",
    "    #get triple feat\n",
    "    tplist = preprocess.triple(storypath)\n",
    "    tplist = list(set(tplist))\n",
    "    #remove leading The/A's in the sematic list\n",
    "    tplist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in tplist]\n",
    "    pattern='|'.join(tplist)\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace(')|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "\n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['TP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['TP'] = corpus['TP'].replace({True:1, False:0})\n",
    "\n",
    "    # get conceptnet feat\n",
    "    urlreq = 'https://api.conceptnet.io/c/en/'+corpus['head_of_head']\n",
    "\n",
    "    #default no presence of person mentioned\n",
    "    corpus['CN'] = 0\n",
    "\n",
    "    for i in range(len(urlreq)):\n",
    "\n",
    "        #make request to concept net api\n",
    "        response = requests.get(urlreq[i])\n",
    "        obj = response.json()\n",
    "        #get list of edges\n",
    "        cnlist = [edge['@id'] for edge in obj['edges']]\n",
    "\n",
    "        #if person is in list then flag\n",
    "        if any('person' in s for s in cnlist):\n",
    "            val = 1\n",
    "            corpus['CN'][i]=val\n",
    "    \n",
    "    #create feature for term freq\n",
    "    tf_dict = preprocess.term_freq(storypath)\n",
    "    corpus['TF'] = corpus['head_of_head'].map(tf_dict)\n",
    "\n",
    "    #create feature that contains keyword extraction score from yake\n",
    "    f = open(storypath, 'r', encoding='ISO-8859-1')\n",
    "    text = f.read()\n",
    "    f.close()  \n",
    "\n",
    "    kw_extractor = yake.KeywordExtractor(top=100)\n",
    "    keywords = dict(kw_extractor.extract_keywords(text))\n",
    "    corpus['YK_SC'] = corpus['head_of_head'].map(keywords)\n",
    "    # corpus['YK_SC'] = corpus['chain_head'].map(keywords)\n",
    "    corpus['YK_SC'] = corpus['YK_SC'].fillna(100)\n",
    "\n",
    "    #append to dataframe\n",
    "    CEN_data = pd.concat([CEN_data, corpus], ignore_index=True)\n",
    "\n",
    "CEN_data.to_csv('Data/CEN.csv')\n",
    "CEN_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Features from Intermediate File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything|The|you|them|one|lady|daughter|debtors|devil|Satan|but|there|Hey|women|and|There|where|we|Pack|princess|king|,|job|It|We|How|Out|They||tavern|how|brother|That|what|thirteen|Wander|they|\"|Order|hammers|spirits|wandered|No|served|soldier|head|everything|many|foreign|road|has|he|it|devils|You|kind|heart|But|that|He|spirit|I|his|Each|she|Lord|who|What|Do|\\'s'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENcopath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "CENInter = src_path + '/output/IntermediateFilesCEN/'\n",
    "ONInter = src_path + '/output/IntermediateFilesON/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "PL_Int_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "for n in range(1,47):\n",
    "# for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = PLcopath +'/story' + str(n) + '.txt'\n",
    "    storypath = PLpath + '/story' + str(n) + '.txt'\n",
    "    storyid = 'story'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    #read in from intermediate files\n",
    "    #list of features\n",
    "    features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    for f in features:\n",
    "        #empty list\n",
    "        feat = []\n",
    "        with open(PLInter + f + 'FeatureBoolean'+'/Story' + str(n) + '.txt', 'r') as doc:\n",
    "            for line in doc:\n",
    "                feat.append(eval(line.rstrip()))\n",
    "    \n",
    "        corpus[f] = feat\n",
    "    \n",
    "    #creat feature for term freq\n",
    "    tf_dict = preprocess.term_freq(storypath)\n",
    "    corpus['TF'] = corpus['head_of_head'].map(tf_dict)\n",
    "\n",
    "    #create feature that contains keyword extraction score from yake\n",
    "    f = open(storypath, 'r', encoding='ISO-8859-1')\n",
    "    text = f.read()\n",
    "    f.close()  \n",
    "\n",
    "    kw_extractor = yake.KeywordExtractor(top=100)\n",
    "    keywords = dict(kw_extractor.extract_keywords(text))\n",
    "    corpus['YK_SC'] = corpus['head_of_head'].map(keywords)\n",
    "    corpus['YK_SC'] = corpus['YK_SC'].fillna(100)\n",
    "\n",
    "    #append to dataframe\n",
    "    PL_Int_data = pd.concat([PL_Int_data, corpus], ignore_index=True)\n",
    "PL_Int_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CEN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "import yake\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENcopath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "CENInter = src_path + '/output/IntermediateFilesCEN/'\n",
    "ONInter = src_path + '/output/IntermediateFilesON/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "CEN_Int_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "for n in range(1,31):\n",
    "# for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = CENcopath +'/Novel' + str(n) + '.txt'\n",
    "    storypath = CENpath + '/Novel' + str(n) + '.txt'\n",
    "    storyid = 'Novel'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    #read in from intermediate files\n",
    "    #list of features\n",
    "    features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    for f in features:\n",
    "        #empty list\n",
    "        feat = []\n",
    "        with open(CENInter + f + 'FeatureBoolean'+'/Novel' + str(n) + '.txt', 'r') as doc:\n",
    "            for line in doc:\n",
    "                feat.append(eval(line.rstrip()))\n",
    "    \n",
    "        corpus[f] = feat\n",
    "    \n",
    "    #create feature for term freq\n",
    "    tf_dict = preprocess.term_freq(storypath)\n",
    "    corpus['TF'] = corpus['head_of_head'].map(tf_dict)\n",
    "\n",
    "    #create feature that contains keyword extraction score from yake\n",
    "    f = open(storypath, 'r', encoding='ISO-8859-1')\n",
    "    text = f.read()\n",
    "    f.close()  \n",
    "\n",
    "    kw_extractor = yake.KeywordExtractor(top = 100)\n",
    "    keywords = dict(kw_extractor.extract_keywords(text))\n",
    "    # corpus['YK_SC'] = corpus['head_of_head'].map(keywords)\n",
    "    corpus['YK_SC'] = corpus['chain_head'].map(keywords)\n",
    "    corpus['YK_SC'] = corpus['YK_SC'].fillna(100)\n",
    "    \n",
    "    #append to dataframe\n",
    "    CEN_Int_data = pd.concat([CEN_Int_data, corpus], ignore_index=True)\n",
    "\n",
    "CEN_Int_data.to_csv('Data/CENInter.csv')\n",
    "CEN_Int_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PL_data = pd.read('Data/PL.csv')\n",
    "CEN_data = pd.read('Data/CEN.csv')\n",
    "Combo = pd.concat([PL_data, CEN_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expiriments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline Model - Jahan Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86 accuracy with a standard deviation of 0.04\n",
      "0.73 f1 score for character class with a standard deviation of 0.08\n"
     ]
    }
   ],
   "source": [
    "# simple model train\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "PL_data = pd.read_csv('Data/PL.csv')\n",
    "\n",
    "data_y = PL_data[\"character\"].astype('int')\n",
    "data_x = PL_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "rbf_svc_1 = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "#fit\n",
    "rbf_svc_1.fit(X_train, y_train)\n",
    "\n",
    "#save\n",
    "dump(rbf_svc_1, \"models/PLallen_model.joblib\")\n",
    "rbf_svc_1 = load('models/PLallen_model.joblib') \n",
    "\n",
    "cv_results = cross_validate(rbf_svc_1, X_train, y_train, cv = 10, scoring=('f1', 'accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# print(cv_results['train_accuracy'])\n",
    "# print(cv_results['test_accuracy'])\n",
    "# print(cv_results['train_f1'])\n",
    "# print(cv_results['test_f1'])\n",
    "# print(cv_results['test_f1_macro'])\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_results['test_accuracy'].mean(), cv_results['test_accuracy'].std()))\n",
    "print(\"%0.2f f1 score for character class with a standard deviation of %0.2f\" % (cv_results['test_f1'].mean(), cv_results['test_f1'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##CEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97 accuracy with a standard deviation of 0.01\n",
      "0.74 f1 score for character class with a standard deviation of 0.05\n"
     ]
    }
   ],
   "source": [
    "# simple model train\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "CEN_data = pd.read_csv('Data/CEN.csv')\n",
    "\n",
    "data_y = CEN_data[\"character\"].astype('int')\n",
    "data_x = CEN_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "rbf_svc_2 = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "#fit\n",
    "rbf_svc_2.fit(X_train, y_train)\n",
    "\n",
    "#save\n",
    "dump(rbf_svc_2, \"models/CENallen_model.joblib\")\n",
    "rbf_svc_2 = load('models/CENallen_model.joblib') \n",
    "\n",
    "cv_results = cross_validate(rbf_svc_2, X_train, y_train, cv = 10, scoring=('f1', 'accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# print(cv_results['train_accuracy'])\n",
    "# print(cv_results['test_accuracy'])\n",
    "# print(cv_results['train_f1'])\n",
    "# print(cv_results['test_f1'])\n",
    "# print(cv_results['test_f1_macro'])\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_results['test_accuracy'].mean(), cv_results['test_accuracy'].std()))\n",
    "print(\"%0.2f f1 score for character class with a standard deviation of %0.2f\" % (cv_results['test_f1'].mean(), cv_results['test_f1'].std()))\n",
    "# print(\"%0.2f f1 score with a standard deviation of %0.2f\" % (cv_results['test_f1_macro'].mean(), cv_results['test_f1'].std()))\n",
    "# print(\"%0.2f f1 score fro non character class\" % (2*cv_results['test_f1_macro'].mean() - cv_results['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94 accuracy with a standard deviation of 0.01\n",
      "0.67 f1 score for character class with a standard deviation of 0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "PL_data = pd.read_csv('Data/PL.csv')\n",
    "CEN_data = pd.read_csv('Data/CEN.csv')\n",
    "\n",
    "Combo_data = pd.concat([PL_data, CEN_data])\n",
    "\n",
    "data_y = Combo_data[\"character\"].astype('int')\n",
    "data_x = Combo_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "rbf_svc_3 = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "#fit\n",
    "rbf_svc_3.fit(X_train, y_train)\n",
    "\n",
    "#save\n",
    "dump(rbf_svc_3, \"models/Comboallen_model.joblib\")\n",
    "rbf_svc_3 = load('models/Comboallen_model.joblib') \n",
    "\n",
    "cv_results = cross_validate(rbf_svc_3, X_train, y_train, cv = 10, scoring=('f1', 'accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# print(cv_results['train_accuracy'])\n",
    "# print(cv_results['test_accuracy'])\n",
    "# print(cv_results['train_f1'])\n",
    "# print(cv_results['test_f1'])\n",
    "# print(cv_results['test_f1_macro'])\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_results['test_accuracy'].mean(), cv_results['test_accuracy'].std()))\n",
    "print(\"%0.2f f1 score for character class with a standard deviation of %0.2f\" % (cv_results['test_f1'].mean(), cv_results['test_f1'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.878 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.822 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.718 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.718 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.718 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.818 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.839 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.861 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.864 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.850 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.875 total time=   0.1s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.843 total time=   0.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.878 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.853 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.871 total time=   0.1s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.861 total time=   0.3s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.882 total time=   0.3s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.857 total time=   0.2s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.853 total time=   0.4s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.864 total time=   0.1s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.854 total time=   0.1s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.885 total time=   0.1s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.1s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.829 total time=   0.1s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.878 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.850 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, refit= True, verbose=3)\n",
    "\n",
    "PL_data = pd.read_csv('Data/PL.csv')\n",
    "\n",
    "data_y = PL_data[\"character\"].astype('int')\n",
    "data_x = PL_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=100, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###CEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.954 total time=   0.1s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.947 total time=   0.1s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.949 total time=   0.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.948 total time=   0.1s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.958 total time=   0.1s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.954 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.954 total time=   0.1s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.955 total time=   0.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.943 total time=   0.1s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.1s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.943 total time=   0.1s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.1s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.941 total time=   0.1s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.931 total time=   0.1s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.932 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.933 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.933 total time=   0.1s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.932 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.932 total time=   0.1s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.970 total time=   0.1s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.967 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.974 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.970 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.971 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.966 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.971 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.970 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.953 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.953 total time=   0.1s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.948 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.945 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.937 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.939 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.941 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.930 total time=   0.1s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.971 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.967 total time=   0.1s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.969 total time=   0.1s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.977 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.970 total time=   0.1s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.971 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.970 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.977 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.977 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.971 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.968 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.968 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.962 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.968 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.945 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.953 total time=   0.1s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.948 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.971 total time=   0.1s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.966 total time=   0.1s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.961 total time=   0.1s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.974 total time=   0.1s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.969 total time=   0.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.972 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.970 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.971 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.972 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.974 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.959 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.959 total time=   0.1s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.960 total time=   0.1s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.960 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.966 total time=   0.2s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.963 total time=   0.1s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.953 total time=   0.1s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.961 total time=   0.1s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.969 total time=   0.1s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.970 total time=   0.1s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.970 total time=   0.1s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.969 total time=   0.1s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.977 total time=   0.1s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.968 total time=   0.1s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.970 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.971 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.978 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.978 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.970 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.968 total time=   0.1s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.966 total time=   0.1s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.964 total time=   0.1s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.960 total time=   0.1s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.966 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, refit= True, verbose=3)\n",
    "\n",
    "CEN_data = pd.read_csv('Data/CEN.csv')\n",
    "\n",
    "data_y = CEN_data[\"character\"].astype('int')\n",
    "data_x = CEN_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=1000, gamma=0.01)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1372\n",
      "           1       0.85      0.71      0.78        80\n",
      "\n",
      "    accuracy                           0.98      1452\n",
      "   macro avg       0.92      0.85      0.88      1452\n",
      "weighted avg       0.98      0.98      0.98      1452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.926 total time=   0.2s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.934 total time=   0.2s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.938 total time=   0.2s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.927 total time=   0.2s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.925 total time=   0.2s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.919 total time=   0.1s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.921 total time=   0.1s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.927 total time=   0.1s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.915 total time=   0.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.914 total time=   0.1s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.900 total time=   0.2s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.892 total time=   0.2s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.889 total time=   0.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.877 total time=   0.2s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.876 total time=   0.2s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.876 total time=   0.2s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.877 total time=   0.2s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.875 total time=   0.2s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.934 total time=   0.2s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.936 total time=   0.2s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.946 total time=   0.2s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.940 total time=   0.2s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.934 total time=   0.2s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.933 total time=   0.1s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.935 total time=   0.1s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.929 total time=   0.1s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.929 total time=   0.1s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.918 total time=   0.1s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.920 total time=   0.1s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.927 total time=   0.2s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.911 total time=   0.2s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.915 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.896 total time=   0.2s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.2s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.896 total time=   0.2s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.892 total time=   0.2s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.887 total time=   0.2s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.934 total time=   0.2s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.934 total time=   0.2s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.947 total time=   0.2s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.934 total time=   0.2s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.936 total time=   0.1s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.938 total time=   0.1s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.947 total time=   0.1s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.941 total time=   0.1s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.934 total time=   0.1s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.928 total time=   0.1s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.1s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.941 total time=   0.1s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.928 total time=   0.1s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.927 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.911 total time=   0.2s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.914 total time=   0.2s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.923 total time=   0.2s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.911 total time=   0.2s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.908 total time=   0.1s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.937 total time=   0.4s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.930 total time=   0.4s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.948 total time=   0.4s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.934 total time=   0.3s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.926 total time=   0.4s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.936 total time=   0.3s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.946 total time=   0.2s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.938 total time=   0.2s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.934 total time=   0.2s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.935 total time=   0.1s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.1s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.946 total time=   0.1s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.940 total time=   0.1s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.934 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.925 total time=   0.1s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.931 total time=   0.2s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.931 total time=   0.2s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.921 total time=   0.1s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.921 total time=   0.1s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.933 total time=   1.2s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.930 total time=   1.7s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.943 total time=   1.8s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.930 total time=   1.4s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.927 total time=   2.3s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.937 total time=   0.6s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.934 total time=   0.7s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.945 total time=   1.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.938 total time=   0.6s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.927 total time=   0.8s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.937 total time=   0.2s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.937 total time=   0.2s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.947 total time=   0.2s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.943 total time=   0.2s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.934 total time=   0.2s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.925 total time=   0.2s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.938 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.926 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, refit= True, verbose=3)\n",
    "\n",
    "CEN_data = pd.read_csv('Data/CEN.csv')\n",
    "PL_data = pd.read_csv('Data/PL.csv')\n",
    "Combo_data = pd.concat([CEN_data, PL_data])\n",
    "\n",
    "data_y = Combo_data[\"character\"].astype('int')\n",
    "data_x = Combo_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=1000, gamma=0.01)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1736\n",
      "           1       0.83      0.56      0.67       194\n",
      "\n",
      "    accuracy                           0.94      1930\n",
      "   macro avg       0.89      0.77      0.82      1930\n",
      "weighted avg       0.94      0.94      0.94      1930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Yake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87 accuracy with a standard deviation of 0.03\n",
      "0.76 f1 score for character class with a standard deviation of 0.07\n"
     ]
    }
   ],
   "source": [
    "# simple model \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "PL_data = pd.read_csv('Data/PL.csv')\n",
    "\n",
    "data_y = PL_data[\"character\"].astype('int')\n",
    "data_x = PL_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\", \"YK_SC\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "rbf_svc_4 = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "#fit\n",
    "rbf_svc_4.fit(X_train, y_train)\n",
    "\n",
    "#save\n",
    "dump(rbf_svc_4, \"models/PLallen_model_yake.joblib\")\n",
    "rbf_svc_4 = load('models/PLallen_model_yake.joblib') \n",
    "\n",
    "cv_results = cross_validate(rbf_svc_4, X_train, y_train, cv = 10, scoring=('f1', 'accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# print(cv_results['train_accuracy'])\n",
    "# print(cv_results['test_accuracy'])\n",
    "# print(cv_results['train_f1'])\n",
    "# print(cv_results['test_f1'])\n",
    "# print(cv_results['test_f1_macro'])\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_results['test_accuracy'].mean(), cv_results['test_accuracy'].std()))\n",
    "print(\"%0.2f f1 score for character class with a standard deviation of %0.2f\" % (cv_results['test_f1'].mean(), cv_results['test_f1'].std()))\n",
    "# print(\"%0.2f f1 score with a standard deviation of %0.2f\" % (cv_results['test_f1_macro'].mean(), cv_results['test_f1'].std()))\n",
    "# print(\"%0.2f f1 score for non character class\" % (2*cv_results['test_f1_macro'].mean() - cv_results['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###CEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97 accuracy with a standard deviation of 0.01\n",
      "0.70 f1 score for character class with a standard deviation of 0.06\n"
     ]
    }
   ],
   "source": [
    "# simple model \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "CEN_data = pd.read_csv('Data/CEN.csv')\n",
    "\n",
    "data_y = CEN_data[\"character\"].astype('int')\n",
    "data_x = CEN_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\", \"YK_SC\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "rbf_svc_5 = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "#fit\n",
    "rbf_svc_5.fit(X_train, y_train)\n",
    "\n",
    "#save\n",
    "dump(rbf_svc_5, \"models/CENallen_model_yake.joblib\")\n",
    "rbf_svc_5 = load('models/CENallen_model_yake.joblib') \n",
    "\n",
    "cv_results = cross_validate(rbf_svc_5, X_train, y_train, cv = 10, scoring=('f1', 'accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# print(cv_results['train_accuracy'])\n",
    "# print(cv_results['test_accuracy'])\n",
    "# print(cv_results['train_f1'])\n",
    "# print(cv_results['test_f1'])\n",
    "# print(cv_results['test_f1_macro'])\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_results['test_accuracy'].mean(), cv_results['test_accuracy'].std()))\n",
    "print(\"%0.2f f1 score for character class with a standard deviation of %0.2f\" % (cv_results['test_f1'].mean(), cv_results['test_f1'].std()))\n",
    "# print(\"%0.2f f1 score with a standard deviation of %0.2f\" % (cv_results['test_f1_macro'].mean(), cv_results['test_f1'].std()))\n",
    "# print(\"%0.2f f1 score for non character class\" % (2*cv_results['test_f1_macro'].mean() - cv_results['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94 accuracy with a standard deviation of 0.01\n",
      "0.67 f1 score for character class with a standard deviation of 0.05\n"
     ]
    }
   ],
   "source": [
    "# simple model \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "PL_data = pd.read_csv('Data/PL.csv')\n",
    "CEN_data = pd.read_csv('Data/CEN.csv')\n",
    "\n",
    "Combo_data = pd.concat([PL_data, CEN_data])\n",
    "\n",
    "data_y = Combo_data[\"character\"].astype('int')\n",
    "data_x = Combo_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "rbf_svc_6 = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "#fit\n",
    "rbf_svc_6.fit(X_train, y_train)\n",
    "\n",
    "#save\n",
    "dump(rbf_svc_6, \"models/Comboallen_model_yake.joblib\")\n",
    "rbf_svc_6 = load('models/Comboallen_model_yake.joblib') \n",
    "\n",
    "cv_results = cross_validate(rbf_svc_6, X_train, y_train, cv = 10, scoring=('f1', 'accuracy', 'f1_macro'), return_train_score=True)\n",
    "\n",
    "# print(cv_results['train_accuracy'])\n",
    "# print(cv_results['test_accuracy'])\n",
    "# print(cv_results['train_f1'])\n",
    "# print(cv_results['test_f1'])\n",
    "# print(cv_results['test_f1_macro'])\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cv_results['test_accuracy'].mean(), cv_results['test_accuracy'].std()))\n",
    "print(\"%0.2f f1 score for character class with a standard deviation of %0.2f\" % (cv_results['test_f1'].mean(), cv_results['test_f1'].std()))\n",
    "# print(\"%0.2f f1 score with a standard deviation of %0.2f\" % (cv_results['test_f1_macro'].mean(), cv_results['test_f1'].std()))\n",
    "# print(\"%0.2f f1 score for non character class\" % (2*cv_results['test_f1_macro'].mean() - cv_results['test_f1'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('char_ext_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ab110a997218d36eb782d7088a10d031e5f038772d20aa5829c90f0ae252251"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
