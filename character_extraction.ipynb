{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing Features from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:66: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  corpus['SS'] = corpus['head_of_head'].str.contains(pattern)\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_4200/2542963973.py:79: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_4200/2542963973.py:86: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_4200/2542963973.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpusID</th>\n",
       "      <th>character</th>\n",
       "      <th>animacy</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "      <th>SS</th>\n",
       "      <th>NER</th>\n",
       "      <th>WN</th>\n",
       "      <th>DP</th>\n",
       "      <th>TP</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ dragon ,  he ,  he ,  the dragon ,  He ,  hi...</td>\n",
       "      <td>dragon</td>\n",
       "      <td>dragon</td>\n",
       "      <td>43</td>\n",
       "      <td>2.499540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess ,  the tsar 's daughter ,  her ,  h...</td>\n",
       "      <td>princess</td>\n",
       "      <td>princess</td>\n",
       "      <td>23</td>\n",
       "      <td>0.990763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsar ,  tsar ,  father ,  tsar ,  her father...</td>\n",
       "      <td>tsar</td>\n",
       "      <td>tsar</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.065380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess' dog ,  a little dog that had follo...</td>\n",
       "      <td>princess' dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsarina ,  mother ,  tsarina ,  tsarina ]</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ the entire enemy army ,  the enemy army ,  h...</td>\n",
       "      <td>the entire enemy army</td>\n",
       "      <td>army</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.308434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ this ,  the best solution ]</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.604613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ a horse ,  a horse ]</td>\n",
       "      <td>a horse</td>\n",
       "      <td>horse</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.604613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ an even better horse ,  his horse ,  his hor...</td>\n",
       "      <td>an even better horse</td>\n",
       "      <td>horse</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.486142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>story46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ the hand ,  the hand ]</td>\n",
       "      <td>the hand</td>\n",
       "      <td>hand</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.604613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1912 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpusID character animacy  \\\n",
       "0      story1         1       1   \n",
       "1      story1         1       1   \n",
       "2      story1         1       1   \n",
       "3      story1         0       1   \n",
       "4      story1         1       1   \n",
       "...       ...       ...     ...   \n",
       "1907  story46         0       1   \n",
       "1908  story46         0       1   \n",
       "1909  story46         0       1   \n",
       "1910  story46         0       1   \n",
       "1911  story46         0       1   \n",
       "\n",
       "                                            coref_chain  \\\n",
       "0     [ dragon ,  he ,  he ,  the dragon ,  He ,  hi...   \n",
       "1     [ princess ,  the tsar 's daughter ,  her ,  h...   \n",
       "2     [ tsar ,  tsar ,  father ,  tsar ,  her father...   \n",
       "3     [ princess' dog ,  a little dog that had follo...   \n",
       "4           [ tsarina ,  mother ,  tsarina ,  tsarina ]   \n",
       "...                                                 ...   \n",
       "1907  [ the entire enemy army ,  the enemy army ,  h...   \n",
       "1908                      [ this ,  the best solution ]   \n",
       "1909                             [ a horse ,  a horse ]   \n",
       "1910  [ an even better horse ,  his horse ,  his hor...   \n",
       "1911                           [ the hand ,  the hand ]   \n",
       "\n",
       "                   chain_head head_of_head chain_len        CL   SS  NER   WN  \\\n",
       "0                     dragon        dragon        43  2.499540  1.0  0.0  0.0   \n",
       "1                   princess      princess        23  0.990763  1.0  0.0  1.0   \n",
       "2                       tsar          tsar         9 -0.065380  1.0  0.0  1.0   \n",
       "3              princess' dog           dog         4 -0.442574  1.0  0.0  0.0   \n",
       "4                    tsarina       tsarina         4 -0.442574  1.0  0.0  1.0   \n",
       "...                       ...          ...       ...       ...  ...  ...  ...   \n",
       "1907   the entire enemy army          army         7 -0.308434  0.0  0.0  0.0   \n",
       "1908                    this          this         2 -0.604613  1.0  0.0  0.0   \n",
       "1909                 a horse         horse         2 -0.604613  0.0  0.0  0.0   \n",
       "1910    an even better horse         horse         4 -0.486142  0.0  0.0  0.0   \n",
       "1911                the hand          hand         2 -0.604613  0.0  0.0  0.0   \n",
       "\n",
       "       DP   TP   CN  \n",
       "0     1.0  1.0  1.0  \n",
       "1     1.0  1.0  1.0  \n",
       "2     1.0  1.0  1.0  \n",
       "3     1.0  1.0  1.0  \n",
       "4     1.0  1.0  1.0  \n",
       "...   ...  ...  ...  \n",
       "1907  0.0  0.0  0.0  \n",
       "1908  1.0  0.0  0.0  \n",
       "1909  0.0  0.0  0.0  \n",
       "1910  0.0  0.0  0.0  \n",
       "1911  1.0  0.0  0.0  \n",
       "\n",
       "[1912 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('popular')\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "PL_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "for n in range(1,47):\n",
    "# for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = PLcopath +'/story' + str(n) + '.txt'\n",
    "    storypath = PLpath + '/story' + str(n) + '.txt'\n",
    "    storyid = 'story'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    # read in from intermediate files\n",
    "    # list of features\n",
    "    # features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    # for f in features:\n",
    "    #     #empty list\n",
    "    #     feat = []\n",
    "    #     with open(PLInter + f + 'FeatureBoolean'+'/Story' + str(n) + '.txt', 'r') as doc:\n",
    "    #         for line in doc:\n",
    "    #             feat.append(eval(line.rstrip()))\n",
    "    \n",
    "    #     corpus[f] = feat\n",
    "\n",
    "    #get ss feature\n",
    "    sslist = preprocess.semantic_subj(storypath)\n",
    "    #remove leading The/A's in the sematic list\n",
    "    sslist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in sslist]\n",
    "    pattern = '|'.join(sslist)\n",
    "    \n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['SS'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['SS'] = corpus['SS'].replace({True:1, False:0})\n",
    "\n",
    "    #get ner feature\n",
    "    nerlist = preprocess.ner_person(storypath)\n",
    "    pattern = '|'.join(nerlist)\n",
    "\n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['NER'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['NER'] = corpus['NER'].replace({True:1, False:0})\n",
    "\n",
    "    #create binary flag variable for wn feat\n",
    "    #get wordnet synset of head of chain\n",
    "    wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
    "   \n",
    "    #fill blanks with unrelated word to person\n",
    "    wn_input[0] = wn_input[0].fillna(wn.synset('strong.a.01'))\n",
    "   \n",
    "    # get common synonym with person\n",
    "    per = wn.synset('person.n.01')\n",
    "    test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
    "   \n",
    "    # test if head of chain related to person\n",
    "    corpus['WN']= test[0]==per\n",
    "    corpus['WN'] = corpus['WN'].replace({True:1, False:0})\n",
    "\n",
    "    #get dp feat\n",
    "    dplist = preprocess.dep_link(storypath)\n",
    "    dplist = list(set(dplist))\n",
    "    pattern='|'.join(dplist)\n",
    "    #remove punct\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "\n",
    "    #create binary flag variable for dp feat\n",
    "    corpus['DP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['DP'] = corpus['DP'].replace({True:1, False:0})\n",
    "\n",
    "    #get triple feat\n",
    "    tplist = preprocess.triple(storypath)\n",
    "    tplist = list(set(tplist))\n",
    "    #remove leading The/A's in the sematic list\n",
    "    tplist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in tplist]\n",
    "    pattern='|'.join(tplist)\n",
    "\n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['TP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['TP'] = corpus['TP'].replace({True:1, False:0})\n",
    "\n",
    "    # get conceptnet feat\n",
    "    urlreq = 'https://api.conceptnet.io/c/en/'+corpus['head_of_head']\n",
    "\n",
    "    #default no presence of person mentioned\n",
    "    corpus['CN'] = 0\n",
    "\n",
    "    for i in range(len(urlreq)):\n",
    "\n",
    "        #make request to concept net api\n",
    "        response = requests.get(urlreq[i])\n",
    "        obj = response.json()\n",
    "        #get list of edges\n",
    "        cnlist = [edge['@id'] for edge in obj['edges']]\n",
    "\n",
    "        #if person is in list then flag\n",
    "        if any('person' in s for s in cnlist):\n",
    "            val = 1\n",
    "            corpus['CN'][i]=val\n",
    "\n",
    "    #append to dataframe\n",
    "    PL_data = pd.concat([PL_data, corpus], ignore_index=True)\n",
    "\n",
    "PL_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything|The|you|them|one|lady|daughter|debtors|devil|Satan|but|there|Hey|women|and|There|where|we|Pack|princess|king|,|job|It|We|How|Out|They||tavern|how|brother|That|what|thirteen|Wander|they|\"|Order|hammers|spirits|wandered|No|served|soldier|head|everything|many|foreign|road|has|he|it|devils|You|kind|heart|But|that|He|spirit|I|his|Each|she|Lord|who|What|Do|\\'s'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = pattern.replace('?|','')\n",
    "pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Features from Intermediate File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpusID</th>\n",
       "      <th>character</th>\n",
       "      <th>animacy</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "      <th>CN</th>\n",
       "      <th>Dep</th>\n",
       "      <th>NER</th>\n",
       "      <th>SS</th>\n",
       "      <th>Triple</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ dragon ,  he ,  he ,  the dragon ,  He ,  hi...</td>\n",
       "      <td>dragon</td>\n",
       "      <td>dragon</td>\n",
       "      <td>43</td>\n",
       "      <td>2.499540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess ,  the tsar 's daughter ,  her ,  h...</td>\n",
       "      <td>princess</td>\n",
       "      <td>princess</td>\n",
       "      <td>23</td>\n",
       "      <td>0.990763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsar ,  tsar ,  father ,  tsar ,  her father...</td>\n",
       "      <td>tsar</td>\n",
       "      <td>tsar</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.065380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ princess' dog ,  a little dog that had follo...</td>\n",
       "      <td>princess' dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsarina ,  mother ,  tsarina ,  tsarina ]</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>tsarina</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ who is stronger ,  who in this world was str...</td>\n",
       "      <td>who is stronger</td>\n",
       "      <td>stronger</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ dragon's statement ,  a tanner in the city o...</td>\n",
       "      <td>dragon's statement</td>\n",
       "      <td>statement</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>story1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Nikita ,  a tanner in the city of Kiev ,  Ni...</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>39</td>\n",
       "      <td>2.197784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ tsar's coming ,  the tsar went in person to ...</td>\n",
       "      <td>tsar's coming</td>\n",
       "      <td>coming</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ his hands ,  his hands ,  his hands ]</td>\n",
       "      <td>his hands</td>\n",
       "      <td>hands</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.518013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ children ,  five thousand little children , ...</td>\n",
       "      <td>children</td>\n",
       "      <td>children</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.367136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ children's tears ,  their tears ,  tears ,  ...</td>\n",
       "      <td>children's tears</td>\n",
       "      <td>tears</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.442574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Nikita's tears ,  tears ]</td>\n",
       "      <td>Nikita's tears</td>\n",
       "      <td>tears</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ the other ,  the other ]</td>\n",
       "      <td>the other</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>story1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ those who do not know what it is ,  those wh...</td>\n",
       "      <td>those who do not know what it is</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.593452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corpusID character animacy  \\\n",
       "0    story1         1       1   \n",
       "1    story1         1       1   \n",
       "2    story1         1       1   \n",
       "3    story1         0       1   \n",
       "4    story1         1       1   \n",
       "5    story1         0       1   \n",
       "6    story1         0       1   \n",
       "7    story1         1       1   \n",
       "8    story1         0       1   \n",
       "9    story1         0       1   \n",
       "10   story1         0       1   \n",
       "11   story1         0       1   \n",
       "12   story1         0       1   \n",
       "13   story1         0       1   \n",
       "14   story1         0       1   \n",
       "\n",
       "                                          coref_chain  \\\n",
       "0   [ dragon ,  he ,  he ,  the dragon ,  He ,  hi...   \n",
       "1   [ princess ,  the tsar 's daughter ,  her ,  h...   \n",
       "2   [ tsar ,  tsar ,  father ,  tsar ,  her father...   \n",
       "3   [ princess' dog ,  a little dog that had follo...   \n",
       "4         [ tsarina ,  mother ,  tsarina ,  tsarina ]   \n",
       "5   [ who is stronger ,  who in this world was str...   \n",
       "6   [ dragon's statement ,  a tanner in the city o...   \n",
       "7   [ Nikita ,  a tanner in the city of Kiev ,  Ni...   \n",
       "8   [ tsar's coming ,  the tsar went in person to ...   \n",
       "9             [ his hands ,  his hands ,  his hands ]   \n",
       "10  [ children ,  five thousand little children , ...   \n",
       "11  [ children's tears ,  their tears ,  tears ,  ...   \n",
       "12                        [ Nikita's tears ,  tears ]   \n",
       "13                         [ the other ,  the other ]   \n",
       "14  [ those who do not know what it is ,  those wh...   \n",
       "\n",
       "                            chain_head head_of_head chain_len        CL   CN  \\\n",
       "0                              dragon        dragon        43  2.499540  1.0   \n",
       "1                            princess      princess        23  0.990763  1.0   \n",
       "2                                tsar          tsar         9 -0.065380  1.0   \n",
       "3                       princess' dog           dog         4 -0.442574  1.0   \n",
       "4                             tsarina       tsarina         4 -0.442574  1.0   \n",
       "5                     who is stronger      stronger         2 -0.593452  0.0   \n",
       "6                  dragon's statement     statement         3 -0.518013  0.0   \n",
       "7                              Nikita        Nikita        39  2.197784  0.0   \n",
       "8                       tsar's coming        coming         3 -0.518013  0.0   \n",
       "9                           his hands         hands         3 -0.518013  0.0   \n",
       "10                           children      children         5 -0.367136  0.0   \n",
       "11                   children's tears         tears         4 -0.442574  0.0   \n",
       "12                     Nikita's tears         tears         2 -0.593452  0.0   \n",
       "13                          the other         other         2 -0.593452  0.0   \n",
       "14   those who do not know what it is            is         2 -0.593452  0.0   \n",
       "\n",
       "    Dep  NER   SS  Triple   WN  \n",
       "0   1.0  0.0  1.0     1.0  0.0  \n",
       "1   1.0  0.0  1.0     0.0  1.0  \n",
       "2   1.0  0.0  1.0     1.0  1.0  \n",
       "3   1.0  0.0  1.0     1.0  0.0  \n",
       "4   1.0  0.0  1.0     0.0  1.0  \n",
       "5   0.0  0.0  0.0     0.0  0.0  \n",
       "6   0.0  0.0  0.0     0.0  0.0  \n",
       "7   1.0  1.0  1.0     0.0  0.0  \n",
       "8   0.0  0.0  0.0     0.0  0.0  \n",
       "9   1.0  0.0  1.0     0.0  0.0  \n",
       "10  1.0  0.0  1.0     0.0  0.0  \n",
       "11  1.0  0.0  1.0     0.0  0.0  \n",
       "12  1.0  1.0  1.0     0.0  0.0  \n",
       "13  0.0  0.0  0.0     0.0  0.0  \n",
       "14  0.0  0.0  1.0     0.0  0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "PL_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "# for n in range(1,47):\n",
    "for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = PLcopath +'/story' + str(n) + '.txt'\n",
    "    storypath = PLpath + '/story' + str(n) + '.txt'\n",
    "    storyid = 'story'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    #read in from intermediate files\n",
    "    #list of features\n",
    "    features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    for f in features:\n",
    "        #empty list\n",
    "        feat = []\n",
    "        with open(PLInter + f + 'FeatureBoolean'+'/Story' + str(n) + '.txt', 'r') as doc:\n",
    "            for line in doc:\n",
    "                feat.append(eval(line.rstrip()))\n",
    "    \n",
    "        corpus[f] = feat\n",
    "    \n",
    "    #append to dataframe\n",
    "    PL_data = pd.concat([PL_data, corpus], ignore_index=True)\n",
    "PL_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90775194 0.9124031  0.91007752 0.91007752 0.90859799 0.91402014\n",
      " 0.9070488  0.91092177 0.91324555 0.91247095]\n",
      "[0.92361111 0.875      0.90972222 0.90277778 0.90909091 0.8951049\n",
      " 0.92307692 0.91608392 0.86713287 0.88811189]\n",
      "[0.82212257 0.8320951  0.82789318 0.82738095 0.82440476 0.83308271\n",
      " 0.82035928 0.82962963 0.83577713 0.83109118]\n",
      "[0.86419753 0.75675676 0.82191781 0.82051282 0.82191781 0.81012658\n",
      " 0.85333333 0.83783784 0.71641791 0.78947368]\n"
     ]
    }
   ],
   "source": [
    "# simple model \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_y = PL_data[\"character\"].astype('int')\n",
    "data_x = PL_data[[\"CL\", \"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=0)\n",
    "\n",
    "rbf_svc = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "cv_results = cross_validate(rbf_svc, X_train, y_train, cv = 10, scoring=('f1', 'accuracy'), return_train_score=True)\n",
    "\n",
    "print(cv_results['train_accuracy'])\n",
    "print(cv_results['test_accuracy'])\n",
    "print(cv_results['train_f1'])\n",
    "print(cv_results['test_f1'])\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=10, test_size=.2, random_state=42)\n",
    "\n",
    "# C_range = np.logspace(-2,10,13)\n",
    "# gamma_range = np.logspace(-9,3,13)\n",
    "\n",
    "# grid = GridSearchCV(svm.SVC(kernel='rbf'), param_grid=dict(gamma = gamma_range, C= C_range), cv=cv)\n",
    "\n",
    "# grid.fit(X_train,y_train)\n",
    "\n",
    "# print(grid.best_params_, grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87906977 0.88062016 0.8744186  0.87674419 0.87529047 0.87838885\n",
      " 0.88071263 0.87838885 0.87993803 0.88071263]\n",
      "[0.86111111 0.83333333 0.86111111 0.84027778 0.87412587 0.9020979\n",
      " 0.86713287 0.86713287 0.83916084 0.86713287]\n",
      "[0.76435045 0.76876877 0.75748503 0.75650842 0.76005961 0.76319759\n",
      " 0.75862069 0.76390977 0.76691729 0.76807229]\n",
      "[0.74358974 0.65714286 0.75       0.70886076 0.75       0.81081081\n",
      " 0.73239437 0.72463768 0.66666667 0.73972603]\n"
     ]
    }
   ],
   "source": [
    "# simple model \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_y = PL_data[\"character\"].astype('int')\n",
    "data_x = PL_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=0)\n",
    "\n",
    "rbf_svc = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "cv_results = cross_validate(rbf_svc, X_train, y_train, cv = 10, scoring=('f1', 'accuracy'), return_train_score=True)\n",
    "\n",
    "print(cv_results['train_accuracy'])\n",
    "print(cv_results['test_accuracy'])\n",
    "print(cv_results['train_f1'])\n",
    "print(cv_results['test_f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('char_ext_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ab110a997218d36eb782d7088a10d031e5f038772d20aa5829c90f0ae252251"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
