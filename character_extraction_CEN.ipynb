{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing Features from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/eileen/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/tmp/ipykernel_186024/2010361149.py:93: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
      "/tmp/ipykernel_186024/2010361149.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
      "/tmp/ipykernel_186024/2010361149.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['CN'][i]=val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpusID</th>\n",
       "      <th>character</th>\n",
       "      <th>animacy</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "      <th>SS</th>\n",
       "      <th>NER</th>\n",
       "      <th>WN</th>\n",
       "      <th>DP</th>\n",
       "      <th>TP</th>\n",
       "      <th>CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Barold ,  He ,  him ,  Barold 's ,  Barold ,...</td>\n",
       "      <td>Barold</td>\n",
       "      <td>Barold</td>\n",
       "      <td>28</td>\n",
       "      <td>2.837451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Lucia ,  Lucia ,  Lucia ,  Lucia , who had b...</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>17</td>\n",
       "      <td>1.487132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Octavia ,  Octavia ,  I ,  Octavia ,  I ,  M...</td>\n",
       "      <td>Octavia</td>\n",
       "      <td>Octavia</td>\n",
       "      <td>24</td>\n",
       "      <td>2.346426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Lady Theobald 's ,  furious Lady Theobald , ...</td>\n",
       "      <td>Lady Theobald 's</td>\n",
       "      <td>'s</td>\n",
       "      <td>12</td>\n",
       "      <td>0.873350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Octavia and Lord Lansdowne ,  Lord Lansdowne...</td>\n",
       "      <td>Octavia and Lord Lansdowne</td>\n",
       "      <td>Lansdowne</td>\n",
       "      <td>16</td>\n",
       "      <td>1.364375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ them ]</td>\n",
       "      <td>them</td>\n",
       "      <td>them</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ Giovanni 's shoulders ]</td>\n",
       "      <td>Giovanni 's shoulders</td>\n",
       "      <td>shoulders</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ his angry eyes ]</td>\n",
       "      <td>his angry eyes</td>\n",
       "      <td>eyes</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ My beloved ,  I ,  I ,  I ,  Especially I , ...</td>\n",
       "      <td>My beloved</td>\n",
       "      <td>beloved</td>\n",
       "      <td>10</td>\n",
       "      <td>0.812119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ you ]</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5808 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpusID character animacy  \\\n",
       "0      Novel1         1       1   \n",
       "1      Novel1         1       1   \n",
       "2      Novel1         1       1   \n",
       "3      Novel1         1       1   \n",
       "4      Novel1         1       1   \n",
       "...       ...       ...     ...   \n",
       "5803  Novel30         0       0   \n",
       "5804  Novel30         0       0   \n",
       "5805  Novel30         0       0   \n",
       "5806  Novel30         0       1   \n",
       "5807  Novel30         0       1   \n",
       "\n",
       "                                            coref_chain  \\\n",
       "0     [ Barold ,  He ,  him ,  Barold 's ,  Barold ,...   \n",
       "1     [ Lucia ,  Lucia ,  Lucia ,  Lucia , who had b...   \n",
       "2     [ Octavia ,  Octavia ,  I ,  Octavia ,  I ,  M...   \n",
       "3     [ Lady Theobald 's ,  furious Lady Theobald , ...   \n",
       "4     [ Octavia and Lord Lansdowne ,  Lord Lansdowne...   \n",
       "...                                                 ...   \n",
       "5803                                           [ them ]   \n",
       "5804                          [ Giovanni 's shoulders ]   \n",
       "5805                                 [ his angry eyes ]   \n",
       "5806  [ My beloved ,  I ,  I ,  I ,  Especially I , ...   \n",
       "5807                                            [ you ]   \n",
       "\n",
       "                        chain_head head_of_head chain_len        CL   SS  NER  \\\n",
       "0                          Barold        Barold        28  2.837451  0.0  1.0   \n",
       "1                           Lucia         Lucia        17  1.487132  1.0  1.0   \n",
       "2                         Octavia       Octavia        24  2.346426  1.0  1.0   \n",
       "3                Lady Theobald 's            's        12  0.873350  0.0  0.0   \n",
       "4      Octavia and Lord Lansdowne     Lansdowne        16  1.364375  0.0  1.0   \n",
       "...                            ...          ...       ...       ...  ...  ...   \n",
       "5803                         them          them         1 -0.218213  1.0  0.0   \n",
       "5804        Giovanni 's shoulders     shoulders         1 -0.218213  0.0  0.0   \n",
       "5805               his angry eyes          eyes         1 -0.218213  1.0  0.0   \n",
       "5806                   My beloved       beloved        10  0.812119  0.0  0.0   \n",
       "5807                          you           you         1 -0.218213  1.0  0.0   \n",
       "\n",
       "       WN   DP   TP   CN  \n",
       "0     0.0  1.0  1.0  0.0  \n",
       "1     0.0  1.0  1.0  0.0  \n",
       "2     0.0  1.0  1.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  \n",
       "4     0.0  1.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  \n",
       "5803  0.0  1.0  1.0  0.0  \n",
       "5804  0.0  0.0  0.0  0.0  \n",
       "5805  0.0  1.0  0.0  0.0  \n",
       "5806  1.0  0.0  0.0  1.0  \n",
       "5807  0.0  1.0  1.0  0.0  \n",
       "\n",
       "[5808 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('popular')\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENcopath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENTexts'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "CENInter = src_path + '/output/IntermediateFilesCEN/'\n",
    "ONInter = src_path + '/output/IntermediateFilesON/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "CEN_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "for n in range(1,31):\n",
    "# for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = CENcopath +'/Novel' + str(n) + '.txt'\n",
    "    storypath = CENpath + '/Novel' + str(n) + '.txt'\n",
    "    storyid = 'Novel'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    # read in from intermediate files\n",
    "    # list of features\n",
    "    # features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    # for f in features:\n",
    "    #     #empty list\n",
    "    #     feat = []\n",
    "    #     with open(PLInter + f + 'FeatureBoolean'+'/Story' + str(n) + '.txt', 'r') as doc:\n",
    "    #         for line in doc:\n",
    "    #             feat.append(eval(line.rstrip()))\n",
    "    \n",
    "    #     corpus[f] = feat\n",
    "\n",
    "    #get ss feature\n",
    "    sslist = preprocess.semantic_subj(storypath)\n",
    "    #remove leading The/A's in the sematic list\n",
    "    sslist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in sslist]\n",
    "    pattern = '|'.join(sslist)\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "    \n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['SS'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['SS'] = corpus['SS'].replace({True:1, False:0})\n",
    "\n",
    "    #get ner feature\n",
    "    nerlist = preprocess.ner_person(storypath)\n",
    "    pattern = '|'.join(nerlist)\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "    pattern = pattern.replace('[','')\n",
    "    pattern = pattern.replace(']','')\n",
    "\n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['NER'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['NER'] = corpus['NER'].replace({True:1, False:0})\n",
    "\n",
    "\n",
    "    #create binary flag variable for wn feat\n",
    "    #get wordnet synset of head of chain\n",
    "    wn_input = corpus['head_of_head'].apply(lambda word: pd.Series(wn.synsets(word)))\n",
    "   \n",
    "    #fill blanks with unrelated word to person\n",
    "    wn_input[0] = wn_input[0].fillna(wn.synset('strong.a.01'))\n",
    "   \n",
    "    # get common synonym with person\n",
    "    per = wn.synset('person.n.01')\n",
    "    test = wn_input[0].apply(lambda syn: pd.Series(syn.lowest_common_hypernyms(per)))\n",
    "   \n",
    "    # test if head of chain related to person\n",
    "    corpus['WN']= test[0]==per\n",
    "    corpus['WN'] = corpus['WN'].replace({True:1, False:0})\n",
    "\n",
    "    #get dp feat\n",
    "    dplist = preprocess.dep_link(storypath)\n",
    "    dplist = list(set(dplist))\n",
    "    pattern='|'.join(dplist)\n",
    "    #remove punct\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace(')|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "\n",
    "    #create binary flag variable for dp feat\n",
    "    corpus['DP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['DP'] = corpus['DP'].replace({True:1, False:0})\n",
    "\n",
    "    #get triple feat\n",
    "    tplist = preprocess.triple(storypath)\n",
    "    tplist = list(set(tplist))\n",
    "    #remove leading The/A's in the sematic list\n",
    "    tplist = [re.sub('^(The |A )','',s, flags=re.IGNORECASE) for s in tplist]\n",
    "    pattern='|'.join(tplist)\n",
    "    pattern = pattern.replace('?|','')\n",
    "    pattern = pattern.replace('!|','')\n",
    "    pattern = pattern.replace('.|','')\n",
    "    pattern = pattern.replace('(|','')\n",
    "    pattern = pattern.replace(')|','')\n",
    "    pattern = pattern.replace('(','')\n",
    "    pattern = pattern.replace(')','')\n",
    "\n",
    "    #create binary flag variable for ss feat\n",
    "    corpus['TP'] = corpus['head_of_head'].str.contains(pattern)\n",
    "    corpus['TP'] = corpus['TP'].replace({True:1, False:0})\n",
    "\n",
    "    # get conceptnet feat\n",
    "    urlreq = 'https://api.conceptnet.io/c/en/'+corpus['head_of_head']\n",
    "\n",
    "    #default no presence of person mentioned\n",
    "    corpus['CN'] = 0\n",
    "\n",
    "    for i in range(len(urlreq)):\n",
    "\n",
    "        #make request to concept net api\n",
    "        response = requests.get(urlreq[i])\n",
    "        obj = response.json()\n",
    "        #get list of edges\n",
    "        cnlist = [edge['@id'] for edge in obj['edges']]\n",
    "\n",
    "        #if person is in list then flag\n",
    "        if any('person' in s for s in cnlist):\n",
    "            val = 1\n",
    "            corpus['CN'][i]=val\n",
    "\n",
    "    #append to dataframe\n",
    "    CEN_data = pd.concat([CEN_data, corpus], ignore_index=True)\n",
    "\n",
    "CEN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alan|James|Rankeillor|Shaws|James|Thomson|Thomson|D.|A.[36|D. of|D. of|D. of|D. of|D. of|D. of|D. of|D. of|D. of|D. of|D. of|D. of|David|D. of|D. of|D. of|D. of|D. of|D. of|Thomson|God|Thomson|Thompson|Balfour|Pilrig|Pilrig|Thomson|David|Torrance|Ferry|Alan|Alan|Alan|Alan|Alan|Thomson|Thankful|Alan|Rankeillor|Alan|Alan|Providence'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Features from Intermediate File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpusID</th>\n",
       "      <th>character</th>\n",
       "      <th>animacy</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "      <th>CN</th>\n",
       "      <th>Dep</th>\n",
       "      <th>NER</th>\n",
       "      <th>SS</th>\n",
       "      <th>Triple</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Barold ,  He ,  him ,  Barold 's ,  Barold ,...</td>\n",
       "      <td>Barold</td>\n",
       "      <td>Barold</td>\n",
       "      <td>28</td>\n",
       "      <td>2.837451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Lucia ,  Lucia ,  Lucia ,  Lucia , who had b...</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>17</td>\n",
       "      <td>1.487132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Octavia ,  Octavia ,  I ,  Octavia ,  I ,  M...</td>\n",
       "      <td>Octavia</td>\n",
       "      <td>Octavia</td>\n",
       "      <td>24</td>\n",
       "      <td>2.346426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Lady Theobald 's ,  furious Lady Theobald , ...</td>\n",
       "      <td>Lady Theobald 's</td>\n",
       "      <td>'s</td>\n",
       "      <td>12</td>\n",
       "      <td>0.873350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Novel1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Octavia and Lord Lansdowne ,  Lord Lansdowne...</td>\n",
       "      <td>Octavia and Lord Lansdowne</td>\n",
       "      <td>Lansdowne</td>\n",
       "      <td>16</td>\n",
       "      <td>1.364375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ them ]</td>\n",
       "      <td>them</td>\n",
       "      <td>them</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ Giovanni 's shoulders ]</td>\n",
       "      <td>Giovanni 's shoulders</td>\n",
       "      <td>shoulders</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ his angry eyes ]</td>\n",
       "      <td>his angry eyes</td>\n",
       "      <td>eyes</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ My beloved ,  I ,  I ,  I ,  Especially I , ...</td>\n",
       "      <td>My beloved</td>\n",
       "      <td>beloved</td>\n",
       "      <td>10</td>\n",
       "      <td>0.812119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807</th>\n",
       "      <td>Novel30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ you ]</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5808 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpusID character animacy  \\\n",
       "0      Novel1         1       1   \n",
       "1      Novel1         1       1   \n",
       "2      Novel1         1       1   \n",
       "3      Novel1         1       1   \n",
       "4      Novel1         1       1   \n",
       "...       ...       ...     ...   \n",
       "5803  Novel30         0       0   \n",
       "5804  Novel30         0       0   \n",
       "5805  Novel30         0       0   \n",
       "5806  Novel30         0       1   \n",
       "5807  Novel30         0       1   \n",
       "\n",
       "                                            coref_chain  \\\n",
       "0     [ Barold ,  He ,  him ,  Barold 's ,  Barold ,...   \n",
       "1     [ Lucia ,  Lucia ,  Lucia ,  Lucia , who had b...   \n",
       "2     [ Octavia ,  Octavia ,  I ,  Octavia ,  I ,  M...   \n",
       "3     [ Lady Theobald 's ,  furious Lady Theobald , ...   \n",
       "4     [ Octavia and Lord Lansdowne ,  Lord Lansdowne...   \n",
       "...                                                 ...   \n",
       "5803                                           [ them ]   \n",
       "5804                          [ Giovanni 's shoulders ]   \n",
       "5805                                 [ his angry eyes ]   \n",
       "5806  [ My beloved ,  I ,  I ,  I ,  Especially I , ...   \n",
       "5807                                            [ you ]   \n",
       "\n",
       "                        chain_head head_of_head chain_len        CL   CN  Dep  \\\n",
       "0                          Barold        Barold        28  2.837451  0.0  1.0   \n",
       "1                           Lucia         Lucia        17  1.487132  0.0  1.0   \n",
       "2                         Octavia       Octavia        24  2.346426  0.0  1.0   \n",
       "3                Lady Theobald 's            's        12  0.873350  0.0  0.0   \n",
       "4      Octavia and Lord Lansdowne     Lansdowne        16  1.364375  0.0  1.0   \n",
       "...                            ...          ...       ...       ...  ...  ...   \n",
       "5803                         them          them         1 -0.218213  0.0  0.0   \n",
       "5804        Giovanni 's shoulders     shoulders         1 -0.218213  0.0  0.0   \n",
       "5805               his angry eyes          eyes         1 -0.218213  0.0  1.0   \n",
       "5806                   My beloved       beloved        10  0.812119  1.0  0.0   \n",
       "5807                          you           you         1 -0.218213  0.0  0.0   \n",
       "\n",
       "      NER   SS  Triple   WN  \n",
       "0     1.0  1.0     1.0  0.0  \n",
       "1     1.0  1.0     0.0  0.0  \n",
       "2     0.0  1.0     0.0  0.0  \n",
       "3     1.0  0.0     1.0  0.0  \n",
       "4     1.0  1.0     1.0  0.0  \n",
       "...   ...  ...     ...  ...  \n",
       "5803  0.0  1.0     0.0  0.0  \n",
       "5804  1.0  0.0     0.0  0.0  \n",
       "5805  0.0  1.0     0.0  0.0  \n",
       "5806  0.0  0.0     0.0  1.0  \n",
       "5807  0.0  1.0     0.0  0.0  \n",
       "\n",
       "[5808 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from lib import data_utils, preprocess\n",
    "\n",
    "#get path\n",
    "src_path = os.getcwd()\n",
    "\n",
    "datapath = src_path + '/Data/'\n",
    "PLcopath = datapath + 'AnnotatedPLData/PLCoref'\n",
    "PLpath = datapath + 'AnnotatedPLData/PLTexts'\n",
    "CENcopath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "CENpath = datapath + 'AnnotatedCENData/CENCoref'\n",
    "ONpath = datapath + 'AnnotatedONData/ONCoref'\n",
    "\n",
    "PLInter = src_path + '/output/IntermediateFilesPL/'\n",
    "CENInter = src_path + '/output/IntermediateFilesCEN/'\n",
    "ONInter = src_path + '/output/IntermediateFilesON/'\n",
    "\n",
    "#import data\n",
    "\n",
    "#create empty data frame\n",
    "CEN_Int_data = pd.DataFrame(columns=['corpusID', 'character', 'animacy', 'coref_chain', 'chain_head', 'head_of_head', 'chain_len', 'CL'])\n",
    "\n",
    "#append all PL texts and features into one dataframe\n",
    "for n in range(1,31):\n",
    "# for n in range(1,2):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    #get story path\n",
    "    storycopath = CENcopath +'/Novel' + str(n) + '.txt'\n",
    "    storypath = CENpath + '/Novel' + str(n) + '.txt'\n",
    "    storyid = 'Novel'+ str(n)\n",
    "\n",
    "    #read in story\n",
    "    corpus = data_utils.read_story(storycopath)\n",
    "\n",
    "    #read in from intermediate files\n",
    "    #list of features\n",
    "    features = [\"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\"]\n",
    "\n",
    "    for f in features:\n",
    "        #empty list\n",
    "        feat = []\n",
    "        with open(CENInter + f + 'FeatureBoolean'+'/Novel' + str(n) + '.txt', 'r') as doc:\n",
    "            for line in doc:\n",
    "                feat.append(eval(line.rstrip()))\n",
    "    \n",
    "        corpus[f] = feat\n",
    "    \n",
    "    #create feature for term freq\n",
    "    tf_dict = preprocess.term_freq(storypath)\n",
    "    corpus['TF'] = corpus['head_of_head'].map(tf_dict)\n",
    "    \n",
    "    #append to dataframe\n",
    "    CEN_Int_data = pd.concat([CEN_Int_data, corpus], ignore_index=True)\n",
    "CEN_Int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animacy</th>\n",
       "      <th>character</th>\n",
       "      <th>coref_chain</th>\n",
       "      <th>corpusID</th>\n",
       "      <th>chain_head</th>\n",
       "      <th>head_of_head</th>\n",
       "      <th>chain_len</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Barold ,  He ,  him ,  Barold 's ,  Barold ,...</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>Barold</td>\n",
       "      <td>Barold</td>\n",
       "      <td>28</td>\n",
       "      <td>4.387545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Lucia ,  Lucia ,  Lucia ,  Lucia , who had b...</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>Lucia</td>\n",
       "      <td>17</td>\n",
       "      <td>2.454891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Octavia ,  Octavia ,  I ,  Octavia ,  I ,  M...</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>Octavia</td>\n",
       "      <td>Octavia</td>\n",
       "      <td>24</td>\n",
       "      <td>3.684761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Lady Theobald 's ,  furious Lady Theobald , ...</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>Lady Theobald 's</td>\n",
       "      <td>'s</td>\n",
       "      <td>12</td>\n",
       "      <td>1.576412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ Octavia and Lord Lansdowne ,  Lord Lansdowne...</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>Octavia and Lord Lansdowne</td>\n",
       "      <td>Lansdowne</td>\n",
       "      <td>16</td>\n",
       "      <td>2.279195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ you ,  Perhaps we ]</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.180546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ You ,  your ,  she ,  I ,  I ,  I ,  I ,  I ]</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>You</td>\n",
       "      <td>You</td>\n",
       "      <td>8</td>\n",
       "      <td>0.873629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ you ,  you ,  you ,  you ,  He ,  his ,  me ]</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>7</td>\n",
       "      <td>0.697933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ you ,  he ,  He ]</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.004850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ your ,  She ,  her ,  she ,  my ,  she ,  sh...</td>\n",
       "      <td>Novel1</td>\n",
       "      <td>your</td>\n",
       "      <td>your</td>\n",
       "      <td>14</td>\n",
       "      <td>1.927803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     animacy  character                                        coref_chain  \\\n",
       "0          1          1  [ Barold ,  He ,  him ,  Barold 's ,  Barold ,...   \n",
       "2          1          1  [ Lucia ,  Lucia ,  Lucia ,  Lucia , who had b...   \n",
       "3          1          1  [ Octavia ,  Octavia ,  I ,  Octavia ,  I ,  M...   \n",
       "4          1          1  [ Lady Theobald 's ,  furious Lady Theobald , ...   \n",
       "7          1          1  [ Octavia and Lord Lansdowne ,  Lord Lansdowne...   \n",
       "..       ...        ...                                                ...   \n",
       "304        1          0                              [ you ,  Perhaps we ]   \n",
       "308        1          0    [ You ,  your ,  she ,  I ,  I ,  I ,  I ,  I ]   \n",
       "316        1          0    [ you ,  you ,  you ,  you ,  He ,  his ,  me ]   \n",
       "322        1          0                                [ you ,  he ,  He ]   \n",
       "324        1          0  [ your ,  She ,  her ,  she ,  my ,  she ,  sh...   \n",
       "\n",
       "    corpusID                    chain_head head_of_head  chain_len        CL  \n",
       "0     Novel1                       Barold        Barold         28  4.387545  \n",
       "2     Novel1                        Lucia         Lucia         17  2.454891  \n",
       "3     Novel1                      Octavia       Octavia         24  3.684761  \n",
       "4     Novel1             Lady Theobald 's            's         12  1.576412  \n",
       "7     Novel1   Octavia and Lord Lansdowne     Lansdowne         16  2.279195  \n",
       "..       ...                           ...          ...        ...       ...  \n",
       "304   Novel1                          you           you          2 -0.180546  \n",
       "308   Novel1                          You           You          8  0.873629  \n",
       "316   Novel1                          you           you          7  0.697933  \n",
       "322   Novel1                          you           you          3 -0.004850  \n",
       "324   Novel1                         your          your         14  1.927803  \n",
       "\n",
       "[84 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CEN_Int_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/eileen/projects/DeepZen/Char_Ext/character_extraction_CEN.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eileen/projects/DeepZen/Char_Ext/character_extraction_CEN.ipynb#ch0000007?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eileen/projects/DeepZen/Char_Ext/character_extraction_CEN.ipynb#ch0000007?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjoblib\u001b[39;00m \u001b[39mimport\u001b[39;00m dump, load\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/eileen/projects/DeepZen/Char_Ext/character_extraction_CEN.ipynb#ch0000007?line=13'>14</a>\u001b[0m data_y \u001b[39m=\u001b[39m CEN_Int_data[\u001b[39m\"\u001b[39m\u001b[39mcharacter\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eileen/projects/DeepZen/Char_Ext/character_extraction_CEN.ipynb#ch0000007?line=14'>15</a>\u001b[0m data_x \u001b[39m=\u001b[39m CEN_Int_data[[\u001b[39m\"\u001b[39m\u001b[39mCL\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDep\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNER\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTriple\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39manimacy\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/eileen/projects/DeepZen/Char_Ext/character_extraction_CEN.ipynb#ch0000007?line=16'>17</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(data_x, data_y, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CEN_Int_data' is not defined"
     ]
    }
   ],
   "source": [
    "# simple model with their features\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "data_y = CEN_Int_data[\"character\"].astype('int')\n",
    "data_x = CEN_Int_data[[\"CL\", \"CN\", \"Dep\", \"NER\", \"SS\", \"Triple\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=1)\n",
    "\n",
    "rbf_svc = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "#fit\n",
    "rbf_svc.fit(X_train, y_train)\n",
    "\n",
    "#save\n",
    "dump(rbf_svc, \"models/CENjahan_model.joblib\")\n",
    "rbf_svc = load('models/CENjahan_model.joblib') \n",
    "\n",
    "cv_results = cross_validate(rbf_svc, X_train, y_train, cv = 10, scoring=('f1', 'accuracy'), return_train_score=True)\n",
    "\n",
    "print(cv_results['train_accuracy'])\n",
    "print(cv_results['test_accuracy'])\n",
    "print(cv_results['train_f1'])\n",
    "print(cv_results['test_f1'])\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=10, test_size=.2, random_state=42)\n",
    "\n",
    "# C_range = np.logspace(-2,10,13)\n",
    "# gamma_range = np.logspace(-9,3,13)\n",
    "\n",
    "# grid = GridSearchCV(svm.SVC(kernel='rbf'), param_grid=dict(gamma = gamma_range, C= C_range), cv=cv)\n",
    "\n",
    "# grid.fit(X_train,y_train)\n",
    "\n",
    "# print(grid.best_params_, grid.best_score_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97576531 0.97678571 0.97602041 0.97602041 0.97627551 0.97627551\n",
      " 0.9744963  0.97526141 0.97704667 0.97628156]\n",
      "[0.97018349 0.97247706 0.97247706 0.9793578  0.96100917 0.97018349\n",
      " 0.97011494 0.9816092  0.96551724 0.96781609]\n",
      "[0.77855478 0.7908046  0.78341014 0.78341014 0.78718535 0.78321678\n",
      " 0.76958525 0.77598152 0.79357798 0.78718535]\n",
      "[0.75471698 0.76923077 0.72727273 0.80851064 0.60465116 0.69767442\n",
      " 0.73469388 0.84       0.70588235 0.68181818]\n"
     ]
    }
   ],
   "source": [
    "# simple model \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_y = CEN_data[\"character\"].astype('int')\n",
    "data_x = CEN_data[[\"CL\", \"CN\", \"DP\", \"NER\", \"SS\", \"TP\", \"WN\", \"animacy\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, random_state=0)\n",
    "\n",
    "rbf_svc = svm.SVC(kernel = 'rbf', C=.5, gamma=1)\n",
    "\n",
    "cv_results = cross_validate(rbf_svc, X_train, y_train, cv = 10, scoring=('f1', 'accuracy'), return_train_score=True)\n",
    "\n",
    "print(cv_results['train_accuracy'])\n",
    "print(cv_results['test_accuracy'])\n",
    "print(cv_results['train_f1'])\n",
    "print(cv_results['test_f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('char_ext_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ab110a997218d36eb782d7088a10d031e5f038772d20aa5829c90f0ae252251"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
